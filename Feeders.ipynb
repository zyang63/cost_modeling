{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyang63/cost_modeling/blob/main/Feeders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adShk6XI0xfz"
      },
      "source": [
        "# Geometric Analysis in Google Colab\n",
        "This is a code that can analyze STL files for riser locations using voxel meshing and 3D image processing tools. The following cell loads four libraries, trimesh, matplotlib, SimpleITK, and scipy. Trimesh is a python library for meshing which can load stl files and create a voxel mesh which can be analyzed in SimpleITK. Matplotlib is used for visualization, and scipy for matrix maniputlation and image morphological transformations. The cell below loads all of the libraries without output.\n",
        "\n",
        "**NOTE: Running this the first time in the Google environment will take time but subsequent runs will be faster.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8q4DTwrsMGNB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install trimesh\n",
        "!pip install matplotlib\n",
        "!pip install SimpleITK\n",
        "!pip install scipy\n",
        "!pip install numpy-stl\n",
        "!pip install cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "3YVaKHTqXBfQ",
        "outputId": "2606ce9f-3f94-4bc7-f775-fb1b1257dc86"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-152308a7-2381-44a0-b091-9dc6d01a3444\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-152308a7-2381-44a0-b091-9dc6d01a3444\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SA30053 3D MODEL (2).stl to SA30053 3D MODEL (2).stl\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUbtJO572LnW"
      },
      "source": [
        "# Voxelizing the geometry\n",
        "Load the geometry and analyze for the size of the geometry. Set the # of elements for creating the voxel mesh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDEj1DtpXD6n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import trimesh as t\n",
        "from trimesh.voxel import creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0mKIBP9fq-y"
      },
      "outputs": [],
      "source": [
        "# import filepath\n",
        "str_filePath = list(uploaded.keys())[0]\n",
        "geometry = t.load_mesh(str_filePath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6svervh2lq5"
      },
      "source": [
        "## Setting the element count\n",
        "This code sets the element count based on the number of divisions along the maximum length. In this case we are setting 200 divisions along the maximum length. This means that the 2 other dimensions are smaller and will have less elements. The size of the element is reported based on the maximum length found in the geometry (regardless of units) divided by the number of divisions on that length. The example below shows us that if the length is in mm and the number of divisions is 200 that the element size is 2.25mm/cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YGIcBPijYfA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6de0d43-212c-4c33-d291-9aa9ab9a50fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.535\n"
          ]
        }
      ],
      "source": [
        "element_count = 200\n",
        "voxel_size = geometry.extents.max()/element_count\n",
        "print(voxel_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX9V6_8M5LL4"
      },
      "source": [
        "## Meshing\n",
        "Creating the mesh using trimesh. The mesh only sets a 1 for the boundary elements and not inside or outside the stl file. therefore the inside of the mesh needs to be set to 1 for the distance transformation later. Padding is necessary because the geometry touches the boundary and we want the outside geometry to be connected.\n",
        "\n",
        "**Can we do the filling here? To simplify the readability of the code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHtN4C3ggN4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f29299-df6f-4724-c1fe-f8234d382cb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<trimesh.VoxelGrid(201, 144, 63)>\n"
          ]
        }
      ],
      "source": [
        "voxel_surface = t.voxel.creation.voxelize(mesh = geometry, pitch = voxel_size)\n",
        "print(voxel_surface)\n",
        "array_int = voxel_surface.matrix.astype(int)\n",
        "array_pad = np.pad(array_int,((1,1)),'constant')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrrWLNVN5pIN"
      },
      "source": [
        "# Morphological operations, Distance Field, Watershed on mesh\n",
        "As mentioned the geometry as meshed does not set the internal cells only the surface. Thus, the code block below fills the geometry so that further morphological operations can be done. The distance field is just a signed distance field generated using the SimpleITK SingedMaurerDistance function. Maurer et al. created a linear time algorithm for calculated the exact distance field and so is the fastest method for this to date. The watershed algorithm is a morphological operation using the distance field to segment the geometry from the deepest areas of the distance field solution. Typically without filtering there are many small segments near the edge due to mesh irregularities without the initial erosion/dilation step. In addition, there is a upper limit to the number of possible segments based on the number of triangles in the polyhedral geometry that the stl provides. So with finer meshes of an stl geometry expect more isolated segments. This observation works both ways so while it may not be desirable to have moany segments, there is also an upper limit to the total number of possible segments in a given stl geometry thus further refinement is not improving the solution quality.  Increasing the smoothing by erosion/dilation is expected to reduce geometric accuracy at sharp features therefore other strategies will be used to combine watershed segments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYtl9svT6sQh"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "img = sitk.GetImageFromArray(array_pad)\n",
        "seg = sitk.ConnectedComponent(img != img[0,0,0])\n",
        "img_filled = sitk.BinaryFillhole(seg!=0)\n",
        "array_filled = sitk.GetArrayFromImage(img_filled)\n",
        "conndef = ndimage.generate_binary_structure(3, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYR_8gINGmbC"
      },
      "source": [
        "## Erosion and Dilation\n",
        "Instead of filtering the distance field for rough surfaces caused by the numerical operation of creating the distance field from a voxel mesh, this can be smoothed but erosion and dilation of the mesh. The erosion function removes the layers of the geometry by the connectivity structure element generally one layer at a time. Here 1 layer is being removed to begin the distance function within the surface instead of at or ouside the."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsgYjTCL-VnP"
      },
      "outputs": [],
      "source": [
        "array_erosion = ndimage.binary_erosion(array_filled, structure=conndef, iterations=2, mask=None,  border_value=0, origin=0, brute_force=False)\n",
        "array_dilate = ndimage.binary_dilation(array_erosion, structure=conndef, iterations=1, mask=None,  border_value=0, origin=0, brute_force=False)\n",
        "array_erosion_int = array_dilate.astype(int)\n",
        "img_erosion = sitk.GetImageFromArray(array_erosion_int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L2hysgHwZpJ"
      },
      "source": [
        "## Distance Field Calculation\n",
        "This is calculating the distance field for the smoothed geometry prepared from the STL file. Need a reference for the Maurer map this is chosen because its linear time for computing the distance field. Also the other choices for the function should be described briefly including the \"insideIsPositive\", \"squaredDistance\" and \"useImageSpacing\". Typically, it's also useful to describe the input data \"img_erosion\" and the output \"img_dist\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYNZE7N0Q7pt"
      },
      "outputs": [],
      "source": [
        "img_dist = sitk.SignedMaurerDistanceMap(img_erosion != 0, insideIsPositive=False, squaredDistance=False, useImageSpacing=False)\n",
        "array_dist = sitk.GetArrayFromImage(img_dist)\n",
        "array_dist_inside = array_dist\n",
        "array_dist_inside[array_erosion_int != 1] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caRURaCpwrJk"
      },
      "source": [
        "## Watersheds\n",
        "A watershed is a method of image segmentation that partitions an image into regions or segments based on the image intensity or gradient. The goal of watershed segmentation is to separate regions with different intensity or gradient values that correspond to different objects or features in an image.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ7VwBlt1UQc"
      },
      "outputs": [],
      "source": [
        "img_thresh = img_filled != 0\n",
        "img_ws = sitk.MorphologicalWatershed( img_dist, markWatershedLine=True, level=1)\n",
        "img_ws_mark = sitk.Mask( img_ws, sitk.Cast(img_thresh, img_ws.GetPixelID()))\n",
        "array_ws_mark = sitk.GetArrayFromImage(img_ws_mark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAgKjvUVwoMb"
      },
      "source": [
        "# Feeder Analysis Section\n",
        "As discussed above there will likely be more segments for feeder evaluation than is typical in a sand casting process. This is due to the relatively low value of the Bi number associated with a low heat transfer at the surface compared to the thermal conductivity in the casting. This leads to significant diffusion of the thermal hotspots merging geometric centers. Even though this can be predicted with a high degree of accuracy using a real physical model of heat transfer, it is the objective of this work to decouple the geometric effect from the physical property effect. Thus solutions for merging hotspots is sought that do not depend on the properties of the material and instead anticipate geometric correlations that are relevant to the processing conditions. Warriner proposed an adjaceny graph of the segments reducing the information of each to a depth and separation distance. This information can be used to weight the edges of the graph such that each nodal contribution can be ranked and then the connected regions can be grouped using a greedy algorithm. Greedy in the sense that the biggest node then consumes the neighboring ones and then they are taken off the list such that the solution can depend on the node which is chosen at the start. In practice, this method tends to provide asymetric segments which actually is an advanged in creating risers in symmetric parts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOmlzyKq66s-"
      },
      "source": [
        "## Feeder parameter E calculated\n",
        "$$E_{ij} = \\frac{k(m_i+m_j)}{d_{ij}}$$\n",
        "\n",
        "$i$ and $j$ be two connected segments\n",
        "$m$ is value of Euclidean distance transform\n",
        "$d_{ij}$ is the Euclidean distance between two hotspots"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find coordinates of the minimum value in distance field\n",
        "def find_coordinates(array_dist):\n",
        "    indices = np.nonzero(array_dist == array_dist.min())\n",
        "    if indices[0].size == 0:\n",
        "          return None\n",
        "    return indices[0][0], indices[1][0], indices[2][0]"
      ],
      "metadata": {
        "id": "43pEM0J2Z3Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Computed parameter E for all connected segments in the given geometry"
      ],
      "metadata": {
        "id": "Y9cGCB10Z5Tc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR95NBbaeTtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ac2d0f-3c7c-4adf-f16d-7f9d6c90231d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 2, 0.16248836941189237)]\n"
          ]
        }
      ],
      "source": [
        "E_list = []\n",
        "G = array_ws_mark.max() + 1\n",
        "# Loop through all pairs of bounding boxes and check if they intersect\n",
        "for i in range(1, G):\n",
        "  F_i = np.where(array_ws_mark != i, 0, array_ws_mark)\n",
        "  dilated_array_i = ndimage.binary_dilation(F_i, structure=conndef).astype(F_i.dtype)\n",
        "  T_i = np.where(F_i != i, 0, array_dist_inside)\n",
        "  M_i = T_i.min()\n",
        "  coordinates_i = find_coordinates(T_i)\n",
        "  x_i, y_i, z_i = coordinates_i\n",
        "  for j  in range(i+1, G):\n",
        "          F_j = np.where(array_ws_mark != j, 0, array_ws_mark)\n",
        "          dilated_array_j = ndimage.binary_dilation(F_j, structure=conndef).astype(F_j.dtype)\n",
        "          Union =  dilated_array_i + dilated_array_j\n",
        "          if 2 in Union:\n",
        "            T_j = np.where(F_j != j, 0, array_dist_inside)\n",
        "            M_j = T_j.min()\n",
        "            coordinates_j = find_coordinates(T_j)\n",
        "            x_j, y_j, z_j = coordinates_j\n",
        "            # Calculate the distance between i and j using the Euclidean distance formula\n",
        "            E = 1.7*(abs(M_i) + abs(M_j))/np.sqrt((x_i - x_j)**2 + (y_i - y_j)**2 + (z_i - z_j)**2)\n",
        "            E_list.append((i, j, E))\n",
        "print(E_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feeder edge cutting"
      ],
      "metadata": {
        "id": "HSsuyVaGPArJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvYLMM4mxfmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4095031-599c-43b3-e740-19aa8e820a33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 2, 0.16248836941189237)]\n"
          ]
        }
      ],
      "source": [
        "E_list_cut = [tup for tup in E_list if tup[2] >= 0]\n",
        "print(E_list_cut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKOyscsTclSU"
      },
      "source": [
        "## Feeder parameter N calculated\n",
        "$$N_i = m_i \\cdot \\left(1 + \\sum_j E_{ij}\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGPb-W1pNNUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f091021c-a1c0-455a-8f51-f718e3c1fde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(55.35057161749578, 1), (55.35057161749578, 2)]\n"
          ]
        }
      ],
      "source": [
        "N_list = []\n",
        "for i in range(1, G):\n",
        "    F_i = np.where(array_ws_mark != i, 0, array_ws_mark)\n",
        "    T_i = np.where(F_i != i, 0, array_dist_inside)\n",
        "    M_i = T_i.min()\n",
        "    total_weight = 1\n",
        "    for edge in E_list:\n",
        "        if edge[0] == i or edge[1] == i:\n",
        "            total_weight += edge[2]\n",
        "    N = abs(M_i) * ( total_weight * float(voxel_size))\n",
        "    N_list.append((N,i))\n",
        "print(N_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn-aYUE4c763"
      },
      "source": [
        "## Feeder merging calculated\n",
        "The resulting node influence values were sorted in descending order. The sorted list was then looped over, and at each iteration, the current node and all of its adjacent neighbors were assigned to a cluster. This assignment was performed in a greedy manner, such that once a node was assigned to a cluster, it was no longer considered for future assignment. Additionally, any edges linking nodes of different clusters were removed during the clustering process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzXTixPrgtaX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deede869-f09f-4f73-be7e-e6f16855a02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2]\n",
            "[(1, 2)]\n",
            "[[1, 2]]\n",
            "[[1, 2]]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "sorted_N_list = sorted(N_list, reverse=True, key=lambda x: x[0])\n",
        "second_N_list_arr = [x[1] for x in sorted_N_list]\n",
        "print(second_N_list_arr)\n",
        "connected_arr = [(x[0], x[1]) for x in E_list_cut]\n",
        "print(connected_arr)\n",
        "Connected = []\n",
        "for elem in second_N_list_arr:\n",
        "  output_lst = list(set([x[0] for x in connected_arr if elem in x] + [x[1] for x in connected_arr if elem in x]))\n",
        "  Connected.append(output_lst)\n",
        "seen = set()\n",
        "Connected_U = []\n",
        "for a in Connected:\n",
        "    # Check if the current array has already been seen\n",
        "    if tuple(a) not in seen:\n",
        "        seen.add(tuple(a))\n",
        "        Connected_U.append(a)\n",
        "print(Connected_U)\n",
        "result = []\n",
        "\n",
        "for arr in Connected_U:\n",
        "    common_elements = []\n",
        "    for elem in arr:\n",
        "        if elem in second_N_list_arr:\n",
        "            common_elements.append(elem)\n",
        "            second_N_list_arr.remove(elem)\n",
        "    if common_elements:\n",
        "        result.append(common_elements)\n",
        "\n",
        "    # remove empty array from array\n",
        "    if not arr:\n",
        "        Connected_U.remove(arr)\n",
        "# Find the missing elements\n",
        "missing = set(second_N_list_arr) - set(item for sublist in result for item in sublist)\n",
        "# Add missing elements to arr1 separately\n",
        "for element in missing:\n",
        "    result.append([element])\n",
        "# Sort result_1 in ascending order\n",
        "result.sort()\n",
        "# Print the result\n",
        "print(result)\n",
        "num_arrays = len([x for x in result if isinstance(x, list)])\n",
        "print(num_arrays)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss4asWQ3dCh2"
      },
      "source": [
        "## Feeder parameter calculated and export\n",
        "To calculate a feeder's geometry based on connected segments volume, parameters such as length (L), width (W), and thickness (T) of the segment, as well as the maximum Euclidean Distance Transform (EDT) value of the segment and geodesic distances from the hotspot position to surface elements are considered. The loaction of largest EDT value determines the length (L), while the median geodesic distance determines the width (W)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsFtbLL1Nj1U"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "import math\n",
        "stats = sitk.LabelShapeStatisticsImageFilter()\n",
        "stats.Execute(img_ws_mark)\n",
        "for p in range(0, num_arrays):\n",
        "    F = sitk.GetArrayFromImage(img_ws_mark)\n",
        "    F[np.where(~np.isin(F, result[p]))] = 0\n",
        "    T = sitk.GetArrayFromImage(img_dist)\n",
        "    T[array_erosion_int != 1] = 0\n",
        "    T[~np.isin(F, result[p])] = 0\n",
        "    # Find coordinates of the minimum value in T\n",
        "    coordinates = find_coordinates(T)\n",
        "    x, y, z = coordinates\n",
        "    # Find first and last non-zero elements in F\n",
        "    indices = np.where(np.isin(F, result[p]))\n",
        "    if indices[0].size > 0:\n",
        "        x1, y1, z1 = indices[0][0], indices[1][0], indices[2][0]\n",
        "        x2, y2, z2 = indices[0][-1], indices[1][-1], indices[2][-1]\n",
        "    dis_x = (x2 - x1) * float(voxel_size)\n",
        "    dis_y = (y2 - y1) * float(voxel_size)\n",
        "    dis_z = (z2 - z1) * float(voxel_size)\n",
        "    L = max(dis_x, dis_y, dis_z)\n",
        "    W = statistics.median([dis_x, dis_y, dis_z])\n",
        "    T = abs(T.min()) * voxel_size\n",
        "    shape_factors = (L + W) / T\n",
        "    bounds = geometry.bounds\n",
        "    feeders_position = (float(voxel_size) * np.array([x, y, z])) + bounds[0]\n",
        "    num_elements = len(result[p])\n",
        "    total_element_count = 0\n",
        "    for q in range(0, num_elements):\n",
        "        e = result[p][q]\n",
        "        element_count = stats.GetNumberOfPixels(e)\n",
        "        total_element_count += element_count\n",
        "        #print(total_element_count)\n",
        "    segment_volumes = float(total_element_count)*(float(voxel_size)**3)\n",
        "        #print(segment_volumes)\n",
        "    feeders_volume = 2.51 * segment_volumes * (shape_factors ** -0.74)\n",
        "    feeders_radius = (feeders_volume / (3 * math.pi)) ** (1 / 3)\n",
        "    feeders_height = 3 * feeders_radius + T\n",
        "    #print(feeders_height)\n",
        "    cylinder = t.creation.cylinder(radius=feeders_radius, height=feeders_height, sections=50)\n",
        "    cylinder.apply_translation(feeders_position + [0, 0, feeders_height/2])\n",
        "    cylinder.export(f'feeder{p}.stl')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization output"
      ],
      "metadata": {
        "id": "V8qH9GUbMZEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Blender installed"
      ],
      "metadata": {
        "id": "gtW-bz_UNBTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def find(name, path):\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        if name in files:\n",
        "            return os.path.join(os.path.relpath(root,start = os.curdir), name)\n",
        "!wget https://ftp.nluug.nl/pub/graphics/blender/release/Blender3.4/blender-3.4.1-linux-x64.tar.xz -O BlenderDownload.tar.xz\n",
        "!tar xf /content/BlenderDownload.tar.xz\n",
        "blender_path = find('blender', '/content/')\n",
        "print(blender_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qQbtU9FNJDt",
        "outputId": "01c7537b-2ede-400c-c4f1-be1d5ba026b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-19 02:53:10--  https://ftp.nluug.nl/pub/graphics/blender/release/Blender3.4/blender-3.4.1-linux-x64.tar.xz\n",
            "Resolving ftp.nluug.nl (ftp.nluug.nl)... 145.220.21.40, 2001:67c:6ec:221:145:220:21:40\n",
            "Connecting to ftp.nluug.nl (ftp.nluug.nl)|145.220.21.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223772600 (213M) [application/x-tar]\n",
            "Saving to: ‘BlenderDownload.tar.xz’\n",
            "\n",
            "BlenderDownload.tar 100%[===================>] 213.41M  30.8MB/s    in 12s     \n",
            "\n",
            "2023-07-19 02:53:22 (17.7 MB/s) - ‘BlenderDownload.tar.xz’ saved [223772600/223772600]\n",
            "\n",
            "blender-3.4.1-linux-x64/blender\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export visualized colored feeders GLB file"
      ],
      "metadata": {
        "id": "mZM1V1eBM_68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blender Python code which function included geometry transparented and feeders colored"
      ],
      "metadata": {
        "id": "6UtzXhUQCMgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    'import bpy',\n",
        "    'bpy.ops.object.select_all(action=\"SELECT\")',\n",
        "    'bpy.data.objects[\"Camera\"].select_set(False)',\n",
        "    'bpy.data.objects[\"Light\"].select_set(False)',\n",
        "    'bpy.ops.object.delete()',\n",
        "    # Import file path\n",
        "    f'bpy.ops.import_mesh.stl(filepath=\"//content//{str_filePath}\")',\n",
        "    'obj = bpy.context.object',\n",
        "    'obj.color = (0,0,1,1)',\n",
        "    'mat = bpy.data.materials.new(\"0\")',\n",
        "    'mat.use_nodes = True',\n",
        "    'principled = mat.node_tree.nodes[\"Principled BSDF\"]',\n",
        "    'principled.inputs[\"Base Color\"].default_value = (1,1,1,1)',\n",
        "    'principled.inputs[\"Alpha\"].default_value = 0.7',\n",
        "    'obj.data.materials.append(mat)',\n",
        "    'bpy.context.object.active_material.blend_method = \"BLEND\"',\n",
        "]\n",
        "\n",
        "for i in range(0, num_arrays):\n",
        "    data += [\n",
        "        f'bpy.ops.import_mesh.stl(filepath=\"//content//feeder{i}.stl\")',\n",
        "\n",
        "        'obj = bpy.context.object',\n",
        "        'obj.color = (0,0,1,1)',\n",
        "        f'mat = bpy.data.materials.new(\"{i+1}\")',\n",
        "        'mat.use_nodes = True',\n",
        "        'principled = mat.node_tree.nodes[\"Principled BSDF\"]',\n",
        "        'principled.inputs[\"Base Color\"].default_value = (0,0,1,1)',\n",
        "        'obj.data.materials.append(mat)',]\n",
        "\n",
        "        # Output file path\n",
        "data += [\n",
        "'bpy.ops.export_scene.gltf(filepath=\"//content//colored_geometry.glb\")'\n",
        "    ]\n",
        "\n",
        "with open('colored_geometry.py', 'w') as f:\n",
        "    f.write('\\n'.join(data))"
      ],
      "metadata": {
        "id": "oXb-pblFNMik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./$blender_path -b  -noaudio -P \"/content/colored_geometry.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hF9bVu_wNdv-",
        "outputId": "72595e4d-cad0-4a29-9bb0-9d59ee9c3777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blender 3.4.1 (hash 55485cb379f7 built 2022-12-20 00:46:45)\n",
            "Import finished in 0.0039 sec.\n",
            "Import finished in 0.0009 sec.\n",
            "02:53:50 | INFO: Draco mesh compression is available, use library at /content/blender-3.4.1-linux-x64/3.4/python/lib/python3.10/site-packages/libextern_draco.so\n",
            "02:53:51 | INFO: Starting glTF 2.0 export\n",
            "02:53:51 | INFO: Extracting primitive: SA30053 3D MODEL (2)\n",
            "02:53:51 | INFO: Primitives created: 1\n",
            "02:53:51 | INFO: Extracting primitive: feeder0\n",
            "02:53:51 | INFO: Primitives created: 1\n",
            "02:53:51 | INFO: Finished glTF 2.0 export in 0.013018608093261719 s\n",
            "\n",
            "\n",
            "Blender quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script = f\"\"\"\n",
        "import bpy\n",
        "\n",
        "# Delete all objects except for the camera and light\n",
        "bpy.ops.object.select_all(action='SELECT')\n",
        "bpy.data.objects['Camera'].select_set(False)\n",
        "bpy.data.objects['Light'].select_set(False)\n",
        "bpy.ops.object.delete()\n",
        "\n",
        "# Import STL mesh and apply remesh modifier\n",
        "bpy.ops.import_mesh.stl(filepath=\"/content/{str_filePath}\",global_scale=0.1)\n",
        "bpy.ops.object.modifier_add(type='REMESH')\n",
        "bpy.context.object.modifiers[\"Remesh\"].mode = 'VOXEL'\n",
        "bpy.context.object.modifiers[\"Remesh\"].voxel_size = {voxel_size}/10\n",
        "bpy.ops.object.modifier_apply(modifier=\"Remesh\")\n",
        "\n",
        "# Unwrap the mesh using Smart UV Project\n",
        "bpy.ops.object.mode_set(mode='EDIT')\n",
        "bpy.ops.mesh.select_all(action='SELECT')\n",
        "bpy.ops.uv.smart_project()\n",
        "bpy.ops.object.mode_set(mode='OBJECT')\n",
        "\n",
        "# Export the object as an OBJ file\n",
        "for obj in bpy.context.selected_objects:\n",
        "    if obj.type == \"MESH\":\n",
        "        bpy.ops.export_scene.obj(filepath=\"/content/remeshed_uv.obj\", use_triangles=True, use_materials=False,global_scale=10)\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a text file\n",
        "with open('obj-export.py', 'w') as f:\n",
        "    f.write(script)"
      ],
      "metadata": {
        "id": "FrsDi9qxhS14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./$blender_path -b  -noaudio -P \"/content/obj-export.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klj38Fmmhkql",
        "outputId": "2f69fdb6-d533-4226-fb03-f4c91bad9d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blender 3.4.1 (hash 55485cb379f7 built 2022-12-20 00:46:45)\n",
            "Import finished in 0.0040 sec.\n",
            "    (  0.0002 sec |   0.0000 sec) OBJ Export path: '/content/remeshed_uv.obj'\n",
            "Error: Object does not have geometry data\n",
            "          (  0.0005 sec |   0.0001 sec) Finished writing geometry of 'Light'.\n",
            "Error: Object does not have geometry data\n",
            "          (  0.0005 sec |   0.0000 sec) Finished writing geometry of 'Camera'.\n",
            "          (  8.0094 sec |   8.0088 sec) Finished writing geometry of 'SA30053 3D MODEL (2)'.\n",
            "      (  8.0095 sec |   8.0093 sec) Finished exporting geometry, now exporting materials\n",
            "      (  8.0096 sec |   8.0093 sec) OBJ Export Finished\n",
            "Progress: 100.00%\n",
            "\n",
            "\n",
            "Blender quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating the surface texture PNG file\n",
        "\n",
        "The STL risers as well as the remeshed OBJ files have been generated; It is time to generate a texture for the surface of the OBJ file."
      ],
      "metadata": {
        "id": "l1YzyJnivok8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bulk of the Code\n",
        "This is the code that performs the UV-Map operations required to change the color of the texture at the desired locations."
      ],
      "metadata": {
        "id": "66qilCQiybdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Math and Vectors\n",
        "Important math classes that will be used by the code"
      ],
      "metadata": {
        "id": "9GJu8d4HRY4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import cv2\n",
        "from stl import mesh"
      ],
      "metadata": {
        "id": "2-hEs43wT7z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vector2:\n",
        "    def __init__(self, double_X, double_Y):\n",
        "        self.x = double_X\n",
        "        self.y = double_Y\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Vector2({self.x}, {self.y})'\n",
        "\n",
        "\n",
        "def toVector2Array(array_str_X, array_str_Y):\n",
        "\n",
        "    # Get lengths of these arrays\n",
        "    int_len_X = len(array_str_X)\n",
        "    int_len_Y = len(array_str_Y)\n",
        "\n",
        "    # Get minimum one\n",
        "    int_len_min = int_len_X\n",
        "    if int_len_Y < int_len_min:\n",
        "        int_len_min = int_len_Y\n",
        "\n",
        "    array_int_vector2 = np.empty([int_len_min, 2], dtype=object)\n",
        "    array_int_vector2[:, :] = [0, Vector2(0, 0)]\n",
        "\n",
        "    # Iterate from minimum to maximum\n",
        "    for k in range(int_len_min):\n",
        "        # Fetch current values\n",
        "        str_x = array_str_X[k]\n",
        "        str_y = array_str_Y[k]\n",
        "\n",
        "        # Convert to double\n",
        "        double_x = float(str_x)\n",
        "        double_y = float(str_y)\n",
        "\n",
        "        # Build vector\n",
        "        vector2_built = Vector2(double_x, double_y)\n",
        "\n",
        "        # Add to array\n",
        "        array_int_vector2[k][0] = k\n",
        "        array_int_vector2[k][1] = vector2_built\n",
        "\n",
        "        # print('Vec #', k, ' ~ ', double_x, ' ~ ', double_y)\n",
        "\n",
        "    return array_int_vector2"
      ],
      "metadata": {
        "id": "9Sos-GbkxELy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vector3:\n",
        "    def __init__(self, double_X, double_Y, double_Z):\n",
        "        self.x = double_X\n",
        "        self.y = double_Y\n",
        "        self.z = double_Z\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'Vector3({self.x}, {self.y}, {self.z})'\n",
        "\n",
        "    def toUVSpace(self):\n",
        "\n",
        "        # Blender might export the OBJ file with different axes than the STL file\n",
        "        return Vector3(self.x, self.z, -self.y)\n",
        "\n",
        "    def toSTLSpace(self):\n",
        "\n",
        "        # This should reverse 'toUVSpace' operation\n",
        "        return Vector3(self.x, -self.z, self.y)\n",
        "\n",
        "\n",
        "def toVector3Array(array_str_X, array_str_Y, array_str_Z):\n",
        "    # Get lengths of these arrays\n",
        "    int_len_X = len(array_str_X)\n",
        "    int_len_Y = len(array_str_Y)\n",
        "    int_len_Z = len(array_str_Z)\n",
        "\n",
        "    # Get minimum one\n",
        "    int_len_min = int_len_X\n",
        "    if int_len_Y < int_len_min:\n",
        "        int_len_min = int_len_Y\n",
        "    if int_len_Z < int_len_min:\n",
        "        int_len_min = int_len_Z\n",
        "\n",
        "    array_int_vector3 = np.empty([int_len_min, 2], dtype=object)\n",
        "    array_int_vector3[:, :] = [0, Vector3(0, 0, 0)]\n",
        "\n",
        "    # Iterate from minimum to maximum\n",
        "    for k in range(int_len_min):\n",
        "        # Fetch current values\n",
        "        str_x = array_str_X[k]\n",
        "        str_y = array_str_Y[k]\n",
        "        str_z = array_str_Z[k]\n",
        "\n",
        "        # Convert to double\n",
        "        double_x = float(str_x)\n",
        "        double_y = float(str_y)\n",
        "        double_z = float(str_z)\n",
        "\n",
        "        # Build vector\n",
        "        vector3_built = Vector3(double_x, double_y, double_z)\n",
        "\n",
        "        # Add to array\n",
        "        array_int_vector3[k][0] = k\n",
        "        array_int_vector3[k][1] = vector3_built\n",
        "\n",
        "        # print('Vec #', k, ' ~ ', double_x, ' ~ ', double_y, ' ~ ', double_z)\n",
        "\n",
        "    return array_int_vector3"
      ],
      "metadata": {
        "id": "SzQG77AOSO8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMajorBound(uvFace):\n",
        "    if len(uvFace.vertices) == 0:\n",
        "        return Vector3(0, 0, 0)\n",
        "\n",
        "    double_x = uvFace.vertices[0].v.x\n",
        "    double_y = uvFace.vertices[0].v.y\n",
        "    double_z = uvFace.vertices[0].v.z\n",
        "\n",
        "    # Through all the vertices\n",
        "    for uvVertex_vertex in uvFace.vertices:\n",
        "        vector3_v = uvVertex_vertex.v\n",
        "\n",
        "        # Greater than any?\n",
        "        if vector3_v.x > double_x:\n",
        "            double_x = vector3_v.x\n",
        "\n",
        "        # Greater than any?\n",
        "        if vector3_v.y > double_y:\n",
        "            double_y = vector3_v.y\n",
        "\n",
        "        # Greater than any?\n",
        "        if vector3_v.z > double_z:\n",
        "            double_z = vector3_v.z\n",
        "\n",
        "    # Fill info\n",
        "    vector3 = Vector3(double_x, double_y, double_z)\n",
        "    return vector3"
      ],
      "metadata": {
        "id": "OXGPO47gSdgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getMinorBound(uvFace):\n",
        "    if len(uvFace.vertices) == 0:\n",
        "        return Vector3(0, 0, 0)\n",
        "\n",
        "    double_x = uvFace.vertices[0].v.x\n",
        "    double_y = uvFace.vertices[0].v.y\n",
        "    double_z = uvFace.vertices[0].v.z\n",
        "\n",
        "    # Through all the vertices\n",
        "    for uvVertex_vertex in uvFace.vertices:\n",
        "        vector3_v = uvVertex_vertex.v\n",
        "\n",
        "        # Lower than any?\n",
        "        if vector3_v.x < double_x:\n",
        "            double_x = vector3_v.x\n",
        "\n",
        "        # Lower than any?\n",
        "        if vector3_v.y < double_y:\n",
        "            double_y = vector3_v.y\n",
        "\n",
        "        # Lower than any?\n",
        "        if vector3_v.z < double_z:\n",
        "            double_z = vector3_v.z\n",
        "\n",
        "    # Fill info\n",
        "    vector3 = Vector3(double_x, double_y, double_z)\n",
        "    return vector3"
      ],
      "metadata": {
        "id": "5xNlorqySf8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Readers\n",
        "These files read .OBJ, .VTK, and a variety of image files"
      ],
      "metadata": {
        "id": "YmsDg53jSCIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UVVertex:\n",
        "    def __init__(self, vector3_v, vector2_vt):\n",
        "        self.v = vector3_v\n",
        "        self.vt = vector2_vt\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'UVVertex({repr(self.v)}, {repr(self.vt)})'"
      ],
      "metadata": {
        "id": "gQhV8iabSTPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UVFace:\n",
        "    def __init__(self, array_uvVertex_vertices, int_faceIndex):\n",
        "        self.vertices = array_uvVertex_vertices\n",
        "        self.box_min = getMinorBound(self)\n",
        "        self.box_max = getMajorBound(self)\n",
        "        self.adjacent = np.empty(1)\n",
        "        self.index = int_faceIndex\n",
        "\n",
        "    def __repr__(self):\n",
        "        if len(self.vertices) < 1:\n",
        "            return 'empty_UVFace()'\n",
        "\n",
        "        # Flatten the matrix and convert elements to strings\n",
        "        array_flatten = self.vertices.flatten().astype(str)\n",
        "\n",
        "        # Join the string elements using a separator\n",
        "        string_result = ', '.join(array_flatten)\n",
        "\n",
        "        # That should work\n",
        "        return f'UVFace(np.array([{string_result}]), {self.index})'\n",
        "\n",
        "    def resolution(self, int_rows, int_columns):\n",
        "\n",
        "        # Legend says these UVFaces are all 1mm² such that their resolution is\n",
        "        # equal to the number of pixels of their area. This method actually\n",
        "        # returns the number of pixels inside this UVFace\n",
        "\n",
        "        # This faces' bounding box indeed envelops the point.\n",
        "        uvVertex_U = self.vertices[0]\n",
        "        uvVertex_V = self.vertices[1]\n",
        "        uvVertex_W = self.vertices[2]\n",
        "\n",
        "        # Find 2D Vertices\n",
        "        vector2_vtU = uvVertex_U.vt\n",
        "        vector2_vtV = uvVertex_V.vt\n",
        "        vector2_vtW = uvVertex_W.vt\n",
        "\n",
        "        # Identify components\n",
        "        Ux = vector2_vtU.x\n",
        "        Uy = vector2_vtU.y\n",
        "        Vx = vector2_vtV.x\n",
        "        Vy = vector2_vtV.y\n",
        "        Wx = vector2_vtW.x\n",
        "        Wy = vector2_vtW.y\n",
        "\n",
        "        # print('U=({},{}) V=({},{}) W=({},{})'.format(Ux, Uy, Vx, Vy, Wx, Wy))\n",
        "\n",
        "        # Scale to the image sizes\n",
        "        Ux = Ux * int_columns\n",
        "        Vx = Vx * int_columns\n",
        "        Wx = Wx * int_columns\n",
        "\n",
        "        Uy = (1 - Uy) * int_rows\n",
        "        Vy = (1 - Vy) * int_rows\n",
        "        Wy = (1 - Wy) * int_rows\n",
        "\n",
        "        Ax = 0\n",
        "        Ay = 0\n",
        "        Bx = 0\n",
        "        By = 0\n",
        "        Cx = 0\n",
        "        Cy = 0\n",
        "\n",
        "        # Identify order in X coordinate\n",
        "        if Ux <= Vx:\n",
        "            if Ux <= Wx:\n",
        "                if Vx <= Wx:\n",
        "                    # U V W\n",
        "                    Ax = Ux\n",
        "                    Ay = Uy\n",
        "\n",
        "                    Bx = Vx\n",
        "                    By = Vy\n",
        "\n",
        "                    Cx = Wx\n",
        "                    Cy = Wy\n",
        "                else:\n",
        "                    # U W V\n",
        "                    Ax = Ux\n",
        "                    Ay = Uy\n",
        "\n",
        "                    Bx = Wx\n",
        "                    By = Wy\n",
        "\n",
        "                    Cx = Vx\n",
        "                    Cy = Vy\n",
        "\n",
        "            # W comes before U\n",
        "            else:\n",
        "                # W U V\n",
        "                Ax = Wx\n",
        "                Ay = Wy\n",
        "\n",
        "                Bx = Ux\n",
        "                By = Uy\n",
        "\n",
        "                Cx = Vx\n",
        "                Cy = Vy\n",
        "\n",
        "        # V comes before U\n",
        "        else:\n",
        "            if Vx <= Wx:\n",
        "                if Ux <= Wx:\n",
        "                    # V U W\n",
        "                    Ax = Vx\n",
        "                    Ay = Vy\n",
        "\n",
        "                    Bx = Ux\n",
        "                    By = Uy\n",
        "\n",
        "                    Cx = Wx\n",
        "                    Cy = Wy\n",
        "                else:\n",
        "                    # V W U\n",
        "                    Ax = Vx\n",
        "                    Ay = Vy\n",
        "\n",
        "                    Bx = Wx\n",
        "                    By = Wy\n",
        "\n",
        "                    Cx = Ux\n",
        "                    Cy = Uy\n",
        "\n",
        "            # W comes before V\n",
        "            else:\n",
        "                # W V U\n",
        "                Ax = Wx\n",
        "                Ay = Wy\n",
        "\n",
        "                Bx = Vx\n",
        "                By = Vy\n",
        "\n",
        "                Cx = Ux\n",
        "                Cy = Uy\n",
        "\n",
        "        # print('A=({},{}) B=({},{}) C=({},{})'.format(Ax, Ay, Bx, By, Cx, Cy))\n",
        "        # print('Scaled A=({},{}) B=({},{}) C=({},{})'.format(Ax, Ay, Bx + 0.00001, By, Cx + 0.00002, Cy))\n",
        "\n",
        "        # Make sure they are never on the same X\n",
        "        if Ax == Bx:\n",
        "            Bx += 0.00001\n",
        "        if Ax == Cx:\n",
        "            Cx += 0.00002\n",
        "        if Bx == Cx:\n",
        "            Cx += 0.00001\n",
        "\n",
        "        # Find slopes and intercepts\n",
        "        mAB = (By - Ay) / (Bx - Ax)\n",
        "        mAC = (Cy - Ay) / (Cx - Ax)\n",
        "        mBC = (Cy - By) / (Cx - Bx)\n",
        "\n",
        "        bAB = Ay - (mAB * Ax)\n",
        "        bAC = Ay - (mAC * Ax)\n",
        "        bBC = By - (mBC * Bx)\n",
        "\n",
        "        # print('Line AB: [m={}, b={}], AC: [m={}, b={}], BC: [m={}, b={}]'.format(mAB, bAB, mAC, bAC, mBC, bBC))\n",
        "\n",
        "        # Integrate Area\n",
        "        double_area = 0\n",
        "\n",
        "        # If these slopes are equal, the three points are a line\n",
        "        if mAB == mBC:\n",
        "\n",
        "            # Area of their triangle = 0\n",
        "            double_area = 0\n",
        "\n",
        "        else:\n",
        "            # The relation between the slopes decides the integral\n",
        "            if mAB > mBC:\n",
        "\n",
        "                # The triangle has its point upward\n",
        "                double_area = (0.5 * ((Bx * Bx) - (Ax * Ax)) * (mAB - mAC)) + \\\n",
        "                              ((Bx - Ax) * (bAB - bAC)) + \\\n",
        "                              (0.5 * ((Cx * Cx) - (Bx * Bx)) * (mBC - mAC)) + \\\n",
        "                              ((Cx - Bx) * (bBC - bAC))\n",
        "            else:\n",
        "\n",
        "                # The triangle has its point downward\n",
        "                double_area = (0.5 * ((Bx * Bx) - (Ax * Ax)) * (mAC - mAB)) + \\\n",
        "                              ((Bx - Ax) * (bAC - bAB)) + \\\n",
        "                              (0.5 * ((Cx * Cx) - (Bx * Bx)) * (mAC - mBC)) + \\\n",
        "                              ((Cx - Bx) * (bAC - bBC))\n",
        "\n",
        "        # Result\n",
        "        return double_area\n",
        "\n",
        "\n",
        "def empty_UVFace():\n",
        "    return UVFace(np.empty(0, dtype=object), -2)\n",
        "\n",
        "\n",
        "def parse_UVFace(str_indices, array_int_vector3_Vertices, array_int_vector2_TextureVert, int_index):\n",
        "\n",
        "    # Split by whitespaces\n",
        "    array_str_indices = str_indices.split()\n",
        "\n",
        "    # Prepare faces, by default size three\n",
        "    array_uvVertex_vertices = np.empty(len(array_str_indices), dtype=object)\n",
        "\n",
        "    for k in range(len(array_str_indices)):\n",
        "\n",
        "        # Split current line by spaces\n",
        "        str_line = array_str_indices[k]\n",
        "        array_str_line = str_line.split('/')\n",
        "\n",
        "        # First index, V\n",
        "        if len(array_str_line) < 1:\n",
        "            print('Invalid Face Vertex ', str_line)\n",
        "            continue\n",
        "\n",
        "        # Parse string to double yeah\n",
        "        double_v = float(array_str_line[0])\n",
        "\n",
        "        # Round\n",
        "        int_v = round(double_v)\n",
        "\n",
        "        # print('V: ~  ', int_v)\n",
        "        vector3_v = array_int_vector3_Vertices[int_v - 1, 1]\n",
        "\n",
        "        # First index, VT\n",
        "        vector2_vt = Vector2(0, 0)\n",
        "        if len(array_str_line) >= 2:\n",
        "            # Parse string to double yeah\n",
        "            double_vt = float(array_str_line[1])\n",
        "\n",
        "            # Round\n",
        "            int_vt = round(double_vt)\n",
        "\n",
        "            # print('VT: ~  ', int_vt)\n",
        "            vector2_vt = array_int_vector2_TextureVert[int_vt - 1, 1]\n",
        "\n",
        "        # Include new vertex\n",
        "        uvVertex_vertex = UVVertex(vector3_v, vector2_vt)\n",
        "        array_uvVertex_vertices[k] = uvVertex_vertex\n",
        "\n",
        "    # Initialize Adjacent\n",
        "    return UVFace(array_uvVertex_vertices, int_index)"
      ],
      "metadata": {
        "id": "oiFSbooKSWJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UVMap:\n",
        "    def __init__(self, array_uvFace_faces):\n",
        "\n",
        "        # An UVMap, in the end, is just a glorified array of UVFaces\n",
        "        self.faces = array_uvFace_faces\n",
        "\n",
        "    def average_resolution(self, int_rows, int_columns, int_samples):\n",
        "        total_resolution = 0\n",
        "        num_faces = 0\n",
        "        int_total = len(self.faces)\n",
        "        int_faceIndex = 0\n",
        "\n",
        "        # Increase the face index\n",
        "        int_increase = math.floor(int_total / int_samples)\n",
        "        if int_increase < 1:\n",
        "            int_increase = 1\n",
        "\n",
        "        # Sum the resolution of these samples\n",
        "        while int_faceIndex < int_total:\n",
        "\n",
        "            # Identify face\n",
        "            uvFace_face = self.faces[int_faceIndex]\n",
        "            int_faceIndex += int_increase\n",
        "\n",
        "            # This face has been counted\n",
        "            num_faces += 1\n",
        "\n",
        "            # Double because these are triangles and we want the\n",
        "            # resolution of the squares they were part of\n",
        "            total_resolution += 2 * uvFace_face.resolution(int_rows, int_columns)\n",
        "\n",
        "        # Return the average\n",
        "        return total_resolution / num_faces\n",
        "\n",
        "    def corneredBoxFaces(self, vector3_minPoint, vector3_maxPoint, double_tolerance):\n",
        "        # The point of this function is to map 3D space points to faces in 2D space\n",
        "        # by first mapping faces to their bounding boxes.\n",
        "\n",
        "        array_int_uvFace = np.empty([0, 2], dtype=object)\n",
        "\n",
        "        # Extrema switcheroo\n",
        "        mx = vector3_minPoint.x if vector3_minPoint.x < vector3_maxPoint.x else vector3_maxPoint.x\n",
        "        my = vector3_minPoint.y if vector3_minPoint.y < vector3_maxPoint.y else vector3_maxPoint.y\n",
        "        mz = vector3_minPoint.z if vector3_minPoint.z < vector3_maxPoint.z else vector3_maxPoint.z\n",
        "        Mx = vector3_minPoint.x if vector3_minPoint.x > vector3_maxPoint.x else vector3_maxPoint.x\n",
        "        My = vector3_minPoint.y if vector3_minPoint.y > vector3_maxPoint.y else vector3_maxPoint.y\n",
        "        Mz = vector3_minPoint.z if vector3_minPoint.z > vector3_maxPoint.z else vector3_maxPoint.z\n",
        "\n",
        "        # Iterate through every uvFace\n",
        "        int_face_current = 0\n",
        "        int_face_length = len(self.faces)\n",
        "        for int_faceIndex in range(int_face_length):\n",
        "\n",
        "            # Target face\n",
        "            uvFace_observed = self.faces[int_faceIndex]\n",
        "\n",
        "            # Find bounding box\n",
        "            vector3_maxFace = uvFace_observed.box_max\n",
        "            vector3_minFace = uvFace_observed.box_min\n",
        "\n",
        "            # Check if the point is within the tolerance of the bounding box\n",
        "            if (vector3_maxFace.x + double_tolerance) < mx:\n",
        "                continue\n",
        "            if (vector3_maxFace.y + double_tolerance) < my:\n",
        "                continue\n",
        "            if (vector3_maxFace.z + double_tolerance) < mz:\n",
        "                continue\n",
        "            if (vector3_minFace.x - double_tolerance) > Mx:\n",
        "                continue\n",
        "            if (vector3_minFace.y - double_tolerance) > My:\n",
        "                continue\n",
        "            if (vector3_minFace.z - double_tolerance) > Mz:\n",
        "                continue\n",
        "\n",
        "            # This face's bounding box envelops the point.\n",
        "            int_face_current += 1\n",
        "            array_int_uvFace = np.append(array_int_uvFace, [[int_faceIndex, uvFace_observed]], axis=0)\n",
        "\n",
        "        print(f'Cornered Box Faces {array_int_uvFace.shape[0]}/{int_face_length}')\n",
        "        return array_int_uvFace\n",
        "\n",
        "def readOBJFile(str_path):\n",
        "\n",
        "    # Read file, split by newline\n",
        "    with open(str_path, 'r') as f:\n",
        "        str_obj_encoded = f.read()\n",
        "        array_str_obj_encoded = str_obj_encoded.splitlines()\n",
        "\n",
        "    # Count final Vertex and Texture array sizes\n",
        "    int_vertex_count = 0\n",
        "    int_texture_count = 0\n",
        "    int_faces_count = 0\n",
        "    for k in range(len(array_str_obj_encoded)):\n",
        "\n",
        "        # Split current line by spaces\n",
        "        str_line = array_str_obj_encoded[k]\n",
        "        array_str_line = str_line.split()\n",
        "\n",
        "        # Which is its identifier key?\n",
        "        str_ident = array_str_line[0]\n",
        "        if str_ident == 'v':\n",
        "\n",
        "            # Key 'v' ~ Vertex position, requires X Y Z\n",
        "            if len(array_str_line) < 4:\n",
        "                print(f'Invalid Vertex {str_line}')\n",
        "                continue\n",
        "\n",
        "            int_vertex_count += 1\n",
        "\n",
        "        elif str_ident == 'vt':\n",
        "\n",
        "            # Key 'vt' ~ Texture Coordinates, requires U V\n",
        "            if len(array_str_line) < 3:\n",
        "                print(f'Invalid Tex UV {str_line}')\n",
        "                continue\n",
        "\n",
        "            int_texture_count += 1\n",
        "\n",
        "        elif str_ident == 'f':\n",
        "\n",
        "            # Key 'f' ~ Face information, requires one entry at least\n",
        "            if len(array_str_line) < 2:\n",
        "                print(f'Invalid Face {str_line}')\n",
        "                continue\n",
        "\n",
        "            int_faces_count += 1\n",
        "\n",
        "    # print('Counter Vertices: x' + str(int_vertex_count))\n",
        "    # print('Counter Textures: x' + str(int_texture_count))\n",
        "    # print('Counter Faces: x' + str(int_faces_count))\n",
        "\n",
        "    # Store vertices' co-ordinates\n",
        "    array_str_X = np.empty(int_vertex_count)\n",
        "    array_str_Y = np.empty(int_vertex_count)\n",
        "    array_str_Z = np.empty(int_vertex_count)\n",
        "\n",
        "    # Store textures' coordinates\n",
        "    array_str_U = np.empty(int_texture_count)\n",
        "    array_str_V = np.empty(int_texture_count)\n",
        "\n",
        "    # Store face indices\n",
        "    array_str_F = [''] * int_faces_count\n",
        "\n",
        "    if int_texture_count <= 0:\n",
        "        print('[----------------- Error -----------------]')\n",
        "        print('[ OBJ File has no texture information.  ]')\n",
        "        print('[-----------------------------------------]')\n",
        "\n",
        "    # Parse co-ordinates and include them in the arrays\n",
        "    int_vertex_current = 0\n",
        "    int_texture_current = 0\n",
        "    int_face_current = 0\n",
        "    for k in range(len(array_str_obj_encoded)):\n",
        "\n",
        "        # Split current line by spaces\n",
        "        str_line = array_str_obj_encoded[k]\n",
        "        array_str_line = str_line.split()\n",
        "\n",
        "        # Which is its identifier key?\n",
        "        str_ident = array_str_line[0]\n",
        "        if str_ident == 'v':\n",
        "\n",
        "            # Key 'v' ~ Vertex position, requires X Y Z\n",
        "            if len(array_str_line) < 4:\n",
        "                continue\n",
        "\n",
        "            # Fetch observed X Y Z\n",
        "            str_x, str_y, str_z = array_str_line[1:4]\n",
        "\n",
        "            # Add to storage arrays at next index\n",
        "            array_str_X[int_vertex_current] = str_x\n",
        "            array_str_Y[int_vertex_current] = str_y\n",
        "            array_str_Z[int_vertex_current] = str_z\n",
        "            int_vertex_current += 1\n",
        "\n",
        "        elif str_ident == 'vt':\n",
        "\n",
        "            # Key 'vt' ~ Texture Coordinates, requires U V\n",
        "            if len(array_str_line) < 3:\n",
        "                continue\n",
        "\n",
        "            # Fetch observed U V\n",
        "            str_u, str_v = array_str_line[1:3]\n",
        "\n",
        "            # Add to storage arrays at next index\n",
        "            array_str_U[int_texture_current] = str_u\n",
        "            array_str_V[int_texture_current] = str_v\n",
        "            int_texture_current += 1\n",
        "\n",
        "        elif str_ident == 'f':\n",
        "\n",
        "            # Key 'f' ~ Face information, requires one entry at least\n",
        "            if len(array_str_line) < 2:\n",
        "                continue\n",
        "\n",
        "            # Fetch observed U V\n",
        "            str_f = str_line[2::]\n",
        "\n",
        "            # Add to storage arrays at next index\n",
        "            array_str_F[int_face_current] = str_f\n",
        "            int_face_current += 1\n",
        "\n",
        "    # Build maps of Vertex and Textures\n",
        "    array_int_vector3_ver = toVector3Array(array_str_X, array_str_Y, array_str_Z)\n",
        "    array_int_vector2_tex = toVector2Array(array_str_U, array_str_V)\n",
        "\n",
        "    # Create face array and resize\n",
        "    int_faceAmount = len(array_str_F)\n",
        "    array_uvFace_faces = [empty_UVFace()] * int_faceAmount\n",
        "\n",
        "    # Parse and add each face\n",
        "    int_face_current = 0\n",
        "    for k in range(int_faceAmount):\n",
        "\n",
        "        # Current Face?\n",
        "        str_face_indices = array_str_F[k]\n",
        "\n",
        "        if int_face_current % 300 == 0:\n",
        "            print(f'Reading Face #{int_face_current} of #{int_faceAmount}')\n",
        "\n",
        "        # Parse face\n",
        "        uvFace_parsed = parse_UVFace(str_face_indices, array_int_vector3_ver, array_int_vector2_tex, -1)\n",
        "\n",
        "        # Invalid Face ~ less than three vertices\n",
        "        if len(uvFace_parsed.vertices) < 3:\n",
        "            print(f\"Invalid Face: {str_face_indices}\")\n",
        "            continue\n",
        "\n",
        "        # Include\n",
        "        array_uvFace_faces[int_face_current] = uvFace_parsed\n",
        "        uvFace_parsed.index = int_face_current\n",
        "        int_face_current += 1\n",
        "\n",
        "    # Completed (real)\n",
        "    return UVMap(array_uvFace_faces)"
      ],
      "metadata": {
        "id": "HnqwWroYSsZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def betterImRead(str_path, bool_forceRGB=False):\n",
        "\n",
        "    # Read image and identify specs\n",
        "    rgbImage_plainTex = cv2.imread(str_path, cv2.IMREAD_UNCHANGED)\n",
        "    rows = rgbImage_plainTex.shape[0]\n",
        "    columns = rgbImage_plainTex.shape[1]\n",
        "    numberOfColorChannels = 1\n",
        "    if len(rgbImage_plainTex.shape) > 2:\n",
        "      numberOfColorChannels = rgbImage_plainTex.shape[2]\n",
        "\n",
        "    if numberOfColorChannels >= 3:\n",
        "\n",
        "        # It is already RGB\n",
        "        rgbImage = rgbImage_plainTex\n",
        "\n",
        "    elif numberOfColorChannels == 1 and len(rgbImage_plainTex.shape) == 2:\n",
        "\n",
        "        # This is just grayscale\n",
        "        if bool_forceRGB:\n",
        "\n",
        "            # Copy that color channel three times\n",
        "            rgbImage = cv2.merge([rgbImage_plainTex, rgbImage_plainTex, rgbImage_plainTex])\n",
        "        else:\n",
        "\n",
        "            # One color channel is good enough\n",
        "            rgbImage = cv2.cvtColor(rgbImage_plainTex, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # This file format was agony to debug!\n",
        "    elif numberOfColorChannels == 1 and len(rgbImage_plainTex.shape) == 3:\n",
        "\n",
        "        # This is an indexed color map\n",
        "        int_colorChannels = 1 if not bool_forceRGB else 3\n",
        "        rgbImage = np.zeros((rows, columns, int_colorChannels), dtype=np.uint8)\n",
        "\n",
        "        for row in range(rows):\n",
        "            for col in range(columns):\n",
        "                val = rgbImage_plainTex[row, col, 0]\n",
        "                rgbImage[row, col, 0] = cv2.LUT(rgbImage_plainTex, val)\n",
        "\n",
        "                # If not forcing RGB, only one color channel is needed\n",
        "                if not bool_forceRGB:\n",
        "                    continue\n",
        "                rgbImage[row, col, 1] = cv2.LUT(rgbImage_plainTex, val)\n",
        "                rgbImage[row, col, 2] = cv2.LUT(rgbImage_plainTex, val)\n",
        "\n",
        "    return rgbImage"
      ],
      "metadata": {
        "id": "YDjKaZ3NUfJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drawing onto Texture\n",
        "These operations allow the rest of the code to edit RGB texture files easily"
      ],
      "metadata": {
        "id": "Wsz7c6d7V7q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def colorMatch(int_r, int_g, int_b, int_val_r, int_val_g, int_val_b, int_colorChannels):\n",
        "\n",
        "    # No color channels? Technical un-match\n",
        "    if int_colorChannels < 1:\n",
        "        return False\n",
        "\n",
        "    # Check first color channel\n",
        "    if not np.isnan(int_r):\n",
        "\n",
        "        # Compare 'at least'\n",
        "        if int_r < 0 and int_val_r < -int_r:\n",
        "            return False\n",
        "\n",
        "        # Compare Equals r\n",
        "        elif int_val_r != int_r:\n",
        "            return False\n",
        "\n",
        "    # Nan, is it present?\n",
        "    elif int_val_r == 0:\n",
        "        return False\n",
        "\n",
        "    # Only one color channel (and it matched?), we are done.\n",
        "    if int_colorChannels < 2:\n",
        "        return True\n",
        "\n",
        "    # Nan, is it present?\n",
        "    if not np.isnan(int_g):\n",
        "\n",
        "        # Compare 'at least'\n",
        "        if int_g < 0 and int_val_g < -int_g:\n",
        "            return False\n",
        "\n",
        "        # Compare Equals r\n",
        "        elif int_val_g != int_g:\n",
        "            return False\n",
        "\n",
        "    # Nan, is it present?\n",
        "    elif int_val_g == 0:\n",
        "        return False\n",
        "\n",
        "    # Only two color channel (and they matched?), we are done.\n",
        "    if int_colorChannels < 3:\n",
        "        return True\n",
        "\n",
        "    if not np.isnan(int_b):\n",
        "\n",
        "        # Compare 'at least'\n",
        "        if int_b < 0 and int_val_b < -int_b:\n",
        "            return False\n",
        "\n",
        "        # Compare Equals r\n",
        "        elif int_val_b != int_b:\n",
        "            return False\n",
        "\n",
        "    # Nan, is it present?\n",
        "    elif int_val_b == 0:\n",
        "        return False\n",
        "\n",
        "    # Reached the end, success\n",
        "    return True"
      ],
      "metadata": {
        "id": "gFKxP3-qXLdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchRecolor(rgbImage_input, rows, columns, int_tex_r, int_tex_g, int_tex_b, boolean_min, int_r, int_g, int_b):\n",
        "\n",
        "    #\n",
        "    #   This function has two modes:\n",
        "    #\n",
        "    #   NORMAL mode\n",
        "    #       Recolors the pixels that match int_r, int_g, int_b\n",
        "    #       with the color specified int_tex_r, int_tex_g, int_tex_b\n",
        "    #\n",
        "    #   MINIMUM mode\n",
        "    #       Recolors the pixels that match int_r, int_g, int_b\n",
        "    #       with a gray color, the minimum value of any color channel\n",
        "    #       of any pixel in the texture, as long as it is not less\n",
        "    #       than the minimum specifications int_tex_r, int_tex_g, int_tex_b\n",
        "    #\n",
        "\n",
        "    if boolean_min:\n",
        "        int_min = 255\n",
        "\n",
        "        # Identify the minimum colour?\n",
        "        for x in range(columns):\n",
        "            for y in range(rows):\n",
        "\n",
        "                # Is the colour accepted?\n",
        "                int_o_r = rgbImage_input[y, x, 0]\n",
        "                int_o_g = rgbImage_input[y, x, 1]\n",
        "                int_o_b = rgbImage_input[y, x, 2]\n",
        "\n",
        "                if int_o_r < int_tex_r or int_o_g < int_tex_g or int_o_b < int_tex_b:\n",
        "                    continue\n",
        "\n",
        "                # Minimum of acceptable colours\n",
        "                if int_o_r < int_min:\n",
        "                    int_min = int_o_r\n",
        "\n",
        "                if int_o_g < int_min:\n",
        "                    int_min = int_o_g\n",
        "\n",
        "                if int_o_b < int_min:\n",
        "                    int_min = int_o_b\n",
        "\n",
        "        # print(f'Minimum Color Identified ~ {int_min}')\n",
        "\n",
        "        int_tex_r = int_min\n",
        "        int_tex_g = int_min\n",
        "        int_tex_b = int_min\n",
        "\n",
        "    for x in range(columns):\n",
        "        for y in range(rows):\n",
        "\n",
        "            int_val_r = rgbImage_input[y, x, 0]\n",
        "            int_val_g = rgbImage_input[y, x, 1]\n",
        "            int_val_b = rgbImage_input[y, x, 2]\n",
        "\n",
        "            # Must match the color channels\n",
        "            if not colorMatch(int_r, int_g, int_b, int_val_r, int_val_g, int_val_b, 3):\n",
        "                continue\n",
        "\n",
        "            # Change color of that pixel\n",
        "            rgbImage_input[y, x, 0] = int_tex_r\n",
        "            rgbImage_input[y, x, 1] = int_tex_g\n",
        "            rgbImage_input[y, x, 2] = int_tex_b\n",
        "\n",
        "    # Done with these changes\n",
        "    return rgbImage_input"
      ],
      "metadata": {
        "id": "jtXnC8rfXQzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getColor(rgb_image_tex, int_y, int_x, int_channel, int_channels):\n",
        "\n",
        "    if int_channel > int_channels:\n",
        "        return 0\n",
        "\n",
        "    # print(f\"At ~{int_x}, {int_y}, {int_channel} found ~{rgb_image_tex[int_y, int_x, int_channel]}~\")\n",
        "    return int(rgb_image_tex[int_y, int_x, int_channel])"
      ],
      "metadata": {
        "id": "S8NVxKFWXSn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def isPointInFace(vector2_A_png, vector2_B_png, vector2_C_png, x, y):\n",
        "\n",
        "    # Identify coordinates\n",
        "    Ux = vector2_A_png.x\n",
        "    Uy = vector2_A_png.y\n",
        "    Wx = vector2_B_png.x\n",
        "    Wy = vector2_B_png.y\n",
        "    Jx = vector2_C_png.x\n",
        "    Jy = vector2_C_png.y\n",
        "\n",
        "    # TOLERANCE\n",
        "    # ----------------\n",
        "    Tx = (Ux + Wx + Jx) / 3\n",
        "    Ty = (Uy + Wy + Jy) / 3\n",
        "    Kx = ((9 * x) + Tx) / 10\n",
        "    Ky = ((9 * y) + Ty) / 10\n",
        "\n",
        "    # UW dot UK\n",
        "    UWx = Wx - Ux\n",
        "    UWy = Wy - Uy\n",
        "    UKx = Kx - Ux\n",
        "    UKy = Ky - Uy\n",
        "    UJx = Jx - Ux\n",
        "    UJy = Jy - Uy\n",
        "    UW = math.sqrt((UWx * UWx) + (UWy * UWy))\n",
        "    UK = math.sqrt((UKx * UKx) + (UKy * UKy))\n",
        "    UJ = math.sqrt((UJx * UJx) + (UJy * UJy))\n",
        "    angle_UW_UK = math.acos(((UWx * UKx) + (UWy * UKy)) / (UW * UK))\n",
        "    angle_UW_UJ = math.acos(((UWx * UJx) + (UWy * UJy)) / (UW * UJ))\n",
        "\n",
        "    # If the angle WUK exceeds WUJ, the point is for sure outside the triangle.\n",
        "    if angle_UW_UK > angle_UW_UJ:\n",
        "        return False\n",
        "\n",
        "    # WJ dot WK\n",
        "    WJx = Jx - Wx\n",
        "    WJy = Jy - Wy\n",
        "    WKx = Kx - Wx\n",
        "    WKy = Ky - Wy\n",
        "    WUx = Ux - Wx\n",
        "    WUy = Uy - Wy\n",
        "    WJ = math.sqrt((WJx * WJx) + (WJy * WJy))\n",
        "    WK = math.sqrt((WKx * WKx) + (WKy * WKy))\n",
        "    WU = math.sqrt((WUx * WUx) + (WUy * WUy))\n",
        "    angle_WJ_WK = math.acos(((WJx * WKx) + (WJy * WKy)) / (WJ * WK))\n",
        "    angle_WJ_WU = math.acos(((WJx * WUx) + (WJy * WUy)) / (WJ * WU))\n",
        "\n",
        "    # If the angle JWK exceeds JWU, the point is for sure outside the triangle.\n",
        "    if angle_WJ_WK > angle_WJ_WU:\n",
        "        return False\n",
        "\n",
        "    # JU dot JK\n",
        "    JUx = Ux - Jx\n",
        "    JUy = Uy - Jy\n",
        "    JKx = Kx - Jx\n",
        "    JKy = Ky - Jy\n",
        "    JWx = Wx - Jx\n",
        "    JWy = Wy - Jy\n",
        "\n",
        "    # calculating the lengths of the sides JU, JK, and JW\n",
        "    JU = math.sqrt((JUx * JUx) + (JUy * JUy))\n",
        "    JK = math.sqrt((JKx * JKx) + (JKy * JKy))\n",
        "    JW = math.sqrt((JWx * JWx) + (JWy * JWy))\n",
        "\n",
        "    # calculating the angles between vectors JU and JK, and JU and JW\n",
        "    angle_JU_JK = math.acos((JUx * JKx + JUy * JKy) / (JU * JK))\n",
        "    angle_JU_JW = math.acos((JUx * JWx + JUy * JWy) / (JU * JW))\n",
        "\n",
        "    # checking if the angle UJK exceeds UJW to determine if the point is outside the triangle\n",
        "    if angle_JU_JK > angle_JU_JW:\n",
        "        return False\n",
        "\n",
        "    # Not outside any of the angles, this point is thus inside the triangle\n",
        "    return True"
      ],
      "metadata": {
        "id": "rH3oumr9XWx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copyTextureOnto(rgbImage_input, rows, columns, rgbImage_tex, double_scale, int_r, int_g, int_b):\n",
        "\n",
        "    # This will copy the texture of rbgImage_tex onto rbgImage_input,\n",
        "    # replacing areas where the value r/g/b matches exactly the input.\n",
        "    #\n",
        "    # Use NaN as 'any amount of this color' but it must be present\n",
        "    # Use negative numbers as 'at least' such that -5 means 'at least 5'\n",
        "    tex_rows, tex_columns, int_colorChannels = rgbImage_tex.shape\n",
        "    # print(f'IMG {rows}Rx{columns}C')\n",
        "    # print(f'TEX {tex_rows}Rx{tex_columns}C, {int_colorChannels} Channels')\n",
        "\n",
        "    # double_c_ratio = tex_columns / columns;\n",
        "    # double_r_ratio = tex_rows / rows;\n",
        "    # disp(strcat('RAT ~', strcat(num2str(double_r_ratio), strcat('x', num2str(double_c_ratio)))))\n",
        "    int_pixels = 0\n",
        "\n",
        "    for x in range(columns):\n",
        "\n",
        "        if x % 100 == 0:\n",
        "            print(f'Scanning row {x}/{columns}')\n",
        "\n",
        "        for y in range(rows):\n",
        "\n",
        "            int_val_r = rgbImage_input[y, x, 0]\n",
        "            int_val_g = rgbImage_input[y, x, 1]\n",
        "            int_val_b = rgbImage_input[y, x, 2]\n",
        "\n",
        "            # Must match the color channels\n",
        "            if not colorMatch(int_r, int_g, int_b, int_val_r, int_val_g, int_val_b, 3):\n",
        "                continue\n",
        "\n",
        "            # Must find the corresponding pixels on the 'tex' texture, after scaling it.\n",
        "\n",
        "            # Shift input-x to tex-x\n",
        "            double_tex_over_x = x / double_scale\n",
        "            double_tex_over_y = y / double_scale\n",
        "\n",
        "            # Strip out the decimal\n",
        "            double_tex_x_rem = double_tex_over_x - int(double_tex_over_x)\n",
        "            double_tex_y_rem = double_tex_over_y - int(double_tex_over_y)\n",
        "\n",
        "            # Modulate over the width of 'tex'\n",
        "            double_tex_x = np.mod(round(double_tex_over_x - double_tex_x_rem), tex_columns)\n",
        "            double_tex_y = np.mod(round(double_tex_over_y - double_tex_y_rem), tex_rows)\n",
        "\n",
        "            # Identify next pixel\n",
        "            double_tex_x_2 = np.mod(double_tex_x + 1, tex_columns)\n",
        "            double_tex_y_2 = np.mod(double_tex_y + 1, tex_rows)\n",
        "\n",
        "            # disp(strcat('PIX 1-1 ~', strcat(num2str(double_tex_x), strcat(',', num2str(double_tex_y)))))\n",
        "            # disp(strcat('PIX 2-2 ~', strcat(num2str(double_tex_x_2), strcat(',', num2str(double_tex_y_2)))))\n",
        "            # Calculate weights\n",
        "            double_wx1 = 1 - double_tex_x_rem\n",
        "            double_wx2 = double_tex_x_rem\n",
        "            double_wy1 = 1 - double_tex_y_rem\n",
        "            double_wy2 = double_tex_y_rem\n",
        "\n",
        "            # Identify values\n",
        "            int_r_1_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x, 0, int_colorChannels)\n",
        "            int_r_2_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x_2, 0, int_colorChannels)\n",
        "            int_r_1_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x, 0, int_colorChannels)\n",
        "            int_r_2_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x_2, 0, int_colorChannels)\n",
        "\n",
        "            # Weighted sum\n",
        "            int_r_f = (int_r_1_1 * double_wx1 * double_wy1) + (int_r_2_1 * double_wx2 * double_wy1) + (\n",
        "                        int_r_1_2 * double_wx1 * double_wy2) + (int_r_2_2 * double_wx2 * double_wy2)\n",
        "\n",
        "            # Increase pixel\n",
        "            int_pixels = int_pixels + 1\n",
        "\n",
        "            # Change color of that yeah\n",
        "            rgbImage_input[y, x, 0] = int_r_f\n",
        "            if int_colorChannels < 3:\n",
        "\n",
        "                # Just gray apparently\n",
        "                rgbImage_input[y, x, 1] = int_r_f\n",
        "                rgbImage_input[y, x, 2] = int_r_f\n",
        "                continue\n",
        "\n",
        "            int_g_1_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x, 1, int_colorChannels)\n",
        "            int_g_2_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x_2, 1, int_colorChannels)\n",
        "            int_g_1_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x, 1, int_colorChannels)\n",
        "            int_g_2_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x_2, 1, int_colorChannels)\n",
        "\n",
        "            # Weighted sum\n",
        "            int_g_f = (int_g_1_1 * double_wx1 * double_wy1) + (int_g_2_1 * double_wx2 * double_wy1) + (\n",
        "                        int_g_1_2 * double_wx1 * double_wy2) + (int_g_2_2 * double_wx2 * double_wy2)\n",
        "\n",
        "            # Change color of that yeah\n",
        "            rgbImage_input[y, x, 1] = int_g_f\n",
        "\n",
        "            int_b_1_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x, 2, int_colorChannels)\n",
        "            int_b_2_1 = getColor(rgbImage_tex, double_tex_y, double_tex_x_2, 2, int_colorChannels)\n",
        "            int_b_1_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x, 2, int_colorChannels)\n",
        "            int_b_2_2 = getColor(rgbImage_tex, double_tex_y_2, double_tex_x_2, 2, int_colorChannels)\n",
        "\n",
        "            # Weighted sum\n",
        "            int_b_f = (int_b_1_1 * double_wx1 * double_wy1) + (int_b_2_1 * double_wx2 * double_wy1) + (\n",
        "                        int_b_1_2 * double_wx1 * double_wy2) + (int_b_2_2 * double_wx2 * double_wy2)\n",
        "\n",
        "            # Change color\n",
        "            rgbImage_input[y, x, 2] = int_b_f\n",
        "\n",
        "    # Done copying texture\n",
        "    return [rgbImage_input, int_pixels]"
      ],
      "metadata": {
        "id": "jD_FLex3Xcxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fillFace(rgbImage_input, rows, columns, uvFace_textureInfo, int_r, int_g, int_b):\n",
        "    # Assumes that the uvFace is a TRIANGLE\n",
        "\n",
        "    # Find UV Location of the Face in the File\n",
        "    uvVertex_U = uvFace_textureInfo.vertices[0]\n",
        "    uvVertex_V = uvFace_textureInfo.vertices[1]\n",
        "    uvVertex_W = uvFace_textureInfo.vertices[2]\n",
        "\n",
        "    # Find 2D Vertices\n",
        "    vector2_vtU = uvVertex_U.vt\n",
        "    vector2_vtV = uvVertex_V.vt\n",
        "    vector2_vtW = uvVertex_W.vt\n",
        "    vector2_A_png = Vector2(vector2_vtU.x * columns, (1 - vector2_vtU.y) * rows)\n",
        "    vector2_B_png = Vector2(vector2_vtV.x * columns, (1 - vector2_vtV.y) * rows)\n",
        "    vector2_C_png = Vector2(vector2_vtW.x * columns, (1 - vector2_vtW.y) * rows)\n",
        "\n",
        "    # Identify components\n",
        "    Ux = vector2_vtU.x\n",
        "    Uy = vector2_vtU.y\n",
        "    Vx = vector2_vtV.x\n",
        "    Vy = vector2_vtV.y\n",
        "    Wx = vector2_vtW.x\n",
        "    Wy = vector2_vtW.y\n",
        "\n",
        "    # Scale to the image sizes\n",
        "    Ux = Ux * columns\n",
        "    Vx = Vx * columns\n",
        "    Wx = Wx * columns\n",
        "\n",
        "    Uy = (1 - Uy) * rows\n",
        "    Vy = (1 - Vy) * rows\n",
        "    Wy = (1 - Wy) * rows\n",
        "\n",
        "    # Identify order in X coordinate\n",
        "    if Ux <= Vx:\n",
        "        if Ux <= Wx:\n",
        "            if Vx <= Wx:\n",
        "                # U V W\n",
        "                Ax = Ux\n",
        "                Ay = Uy\n",
        "\n",
        "                Bx = Vx\n",
        "                By = Vy\n",
        "\n",
        "                Cx = Wx\n",
        "                Cy = Wy\n",
        "            else:\n",
        "                # U W V\n",
        "                Ax = Ux\n",
        "                Ay = Uy\n",
        "\n",
        "                Bx = Wx\n",
        "                By = Wy\n",
        "\n",
        "                Cx = Vx\n",
        "                Cy = Vy\n",
        "\n",
        "        # W comes before U\n",
        "        else:\n",
        "            # W U V\n",
        "            Ax = Wx\n",
        "            Ay = Wy\n",
        "\n",
        "            Bx = Ux\n",
        "            By = Uy\n",
        "\n",
        "            Cx = Vx\n",
        "            Cy = Vy\n",
        "\n",
        "    # V comes before U\n",
        "    else:\n",
        "        if Vx <= Wx:\n",
        "            if Ux <= Wx:\n",
        "                # V U W\n",
        "                Ax = Vx\n",
        "                Ay = Vy\n",
        "\n",
        "                Bx = Ux\n",
        "                By = Uy\n",
        "\n",
        "                Cx = Wx\n",
        "                Cy = Wy\n",
        "            else:\n",
        "                # V W U\n",
        "                Ax = Vx\n",
        "                Ay = Vy\n",
        "\n",
        "                Bx = Wx\n",
        "                By = Wy\n",
        "\n",
        "                Cx = Ux\n",
        "                Cy = Uy\n",
        "\n",
        "        # W comes before V\n",
        "        else:\n",
        "            # W V U\n",
        "            Ax = Wx\n",
        "            Ay = Wy\n",
        "\n",
        "            Bx = Vx\n",
        "            By = Vy\n",
        "\n",
        "            Cx = Ux\n",
        "            Cy = Uy\n",
        "\n",
        "    # Display the coordinates of points A, B and C\n",
        "    #print(f\"A={Ax}, {Ay}; B={Bx}, {By}; C={Cx}, {Cy}\")\n",
        "\n",
        "    # Make sure they are never on the same X\n",
        "    if Ax == Bx:\n",
        "        Bx = Ax + 0.00001\n",
        "    if Ax == Cx:\n",
        "        Cx = Ax + 0.00002\n",
        "    if Bx == Cx:\n",
        "        Cx = Bx + 0.00001\n",
        "\n",
        "    # Mark a sweet circle\n",
        "    int_x = round((Ax + Bx + Cx) / 3.00)\n",
        "    int_y = round((Ay + By + Cy) / 3.00)\n",
        "\n",
        "    # Gather radius\n",
        "    double_radius = math.sqrt((int_x - Ax) * (int_x - Ax) + (int_y - Ay) * (int_y - Ay))\n",
        "    double_radiusB = math.sqrt((int_x - Bx) * (int_x - Bx) + (int_y - By) * (int_y - By))\n",
        "    double_radiusC = math.sqrt((int_x - Cx) * (int_x - Cx) + (int_y - Cy) * (int_y - Cy))\n",
        "    if double_radius < double_radiusB:\n",
        "        double_radius = double_radiusB\n",
        "    if double_radius < double_radiusC:\n",
        "        double_radius = double_radiusC\n",
        "\n",
        "    double_radius = round(double_radius)\n",
        "\n",
        "    for x in range(int_x - double_radius, int_x + double_radius + 1):\n",
        "        for y in range(int_y - double_radius, int_y + double_radius + 1):\n",
        "\n",
        "            # Distance?\n",
        "            int_xx = x - int_x\n",
        "            int_yy = y - int_y\n",
        "            if math.sqrt(int_xx ** 2 + int_yy ** 2) > double_radius:\n",
        "                # Not drawing a box, drawing a circle!\n",
        "                continue\n",
        "\n",
        "            if math.isnan(y) or math.isnan(x) or y < 0 or x < 0 or y >= rows or x >= columns:\n",
        "                continue\n",
        "\n",
        "            #         print('- x=' + str(x) + '\"')\n",
        "            #         print('- y=' + str(y) + '\"')\n",
        "\n",
        "            # Same color? I sleep\n",
        "            if rgbImage_input[y, x, 0] == int_b \\\n",
        "                    and rgbImage_input[y, x, 1] == int_g \\\n",
        "                    and rgbImage_input[y, x, 2] == int_r:\n",
        "                # No need to color it\n",
        "                continue\n",
        "\n",
        "            # In this face?\n",
        "            if not isPointInFace(vector2_A_png, vector2_B_png, vector2_C_png, x, y):\n",
        "                continue\n",
        "\n",
        "            # Change color of that yeah.\n",
        "            rgbImage_input[y, x, 0] = int_b\n",
        "            rgbImage_input[y, x, 1] = int_g\n",
        "            rgbImage_input[y, x, 2] = int_r\n",
        "\n",
        "    # Complete\n",
        "    return rgbImage_input"
      ],
      "metadata": {
        "id": "5jnd_IxpXku9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Mark Texture"
      ],
      "metadata": {
        "id": "sf5VeAJvXyTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drawCylinder(array_str_riserPaths, uvMap_map, rgbImage_input, rows, columns, double_tolerance):\n",
        "    for int_riser in range(len(array_str_riserPaths)):\n",
        "        print(f'Drawing Riser #{int_riser + 1}')\n",
        "\n",
        "        # Read Cylinder\n",
        "        # This method only supports cylindrical risers, but does so at any 3D rotation.\n",
        "        # It must first identify the axis of the cylinder, it does so by identifying\n",
        "        # the planes of the faces, both perpendicular to this axis:\n",
        "        #\n",
        "        # The geometry of the .STL riser is ultimately given in triangular faces,\n",
        "        # which in turn defines a finite amount of vertex points.\n",
        "        #\n",
        "        # These vertices, they form two circles (defining the top and bottom faces),\n",
        "        # and the centers of these circles is pierced by one line: The axis of the cylinder.\n",
        "        #\n",
        "        # #1 Identify which vertices belong to which plane\n",
        "        #\n",
        "        # #2 All the points in a plane make a circle, find its center.\n",
        "        #\n",
        "        # #3 There are two planes = two centers. The line they make is the axis of the cylinder.\n",
        "        #\n",
        "        # One at this point, the coordinates of the cylinder and its dimensions are readily available.\n",
        "        #\n",
        "        # All is left is to treat the cylinder as a set of points, and apply the same algorithm\n",
        "        # that draws VTK points onto the geometry.\n",
        "\n",
        "        # Read File\n",
        "        discreteGeometry_riser = mesh.Mesh.from_file(array_str_riserPaths[int_riser])\n",
        "        array_vertices = np.unique(discreteGeometry_riser.vectors.reshape((-1, 3)), axis=0)\n",
        "        int_points = len(array_vertices)\n",
        "\n",
        "        if int_points < 1:\n",
        "            # Log error\n",
        "            print('Empty STL Geometry at ~', array_str_riserPaths[int_riser])\n",
        "            continue\n",
        "\n",
        "        # Plane A normal\n",
        "        PAx = 0\n",
        "        PAy = 0\n",
        "        PAz = 0\n",
        "\n",
        "        # Plane A point is just the very first point in load\n",
        "        Ax = array_vertices[0, 0]\n",
        "        Ay = array_vertices[0, 1]\n",
        "        Az = array_vertices[0, 2]\n",
        "\n",
        "        # Identify Cylinder, skip the very first point as it is already 'A'\n",
        "        double_slantTolerance = 0.015\n",
        "        for i in range(1, int_points - 1):\n",
        "\n",
        "            # Most points will have their chance to be B\n",
        "            Bx = array_vertices[i, 0]\n",
        "            By = array_vertices[i, 1]\n",
        "            Bz = array_vertices[i, 2]\n",
        "\n",
        "            # Accept\n",
        "            bool_accepted = False\n",
        "\n",
        "            for j in range(i + 1, int_points - 1):\n",
        "\n",
        "                # Most points will have their chance to be C\n",
        "                Cx = array_vertices[j, 0]\n",
        "                Cy = array_vertices[j, 1]\n",
        "                Cz = array_vertices[j, 2]\n",
        "\n",
        "                # Plane vector direction yeah\n",
        "                Px = ((By - Ay) * (Cz - Az)) - ((Bz - Az) * (Cy - Ay))\n",
        "                Py = ((Bz - Az) * (Cx - Ax)) - ((Bx - Ax) * (Cz - Az))\n",
        "                Pz = ((Bx - Ax) * (Cy - Ay)) - ((By - Ay) * (Cx - Ax))\n",
        "\n",
        "                # How many points in plane / how many not\n",
        "                int_success = 3\n",
        "\n",
        "                # Do other points lie in this plane?\n",
        "                for k in range(1, int_points - 1):\n",
        "\n",
        "                    # Except the two points being evaluated, and the first one k=0 (would be point A)\n",
        "                    if k == i or k == j:\n",
        "                        continue\n",
        "\n",
        "                    # Identify coordinates\n",
        "                    Vx = array_vertices[k, 0]\n",
        "                    Vy = array_vertices[k, 1]\n",
        "                    Vz = array_vertices[k, 2]\n",
        "\n",
        "                    # Direction within plane\n",
        "                    AVx = Vx - Ax\n",
        "                    AVy = Vy - Ay\n",
        "                    AVz = Vz - Az\n",
        "\n",
        "                    # Plane equation\n",
        "                    double_p = (AVx * Px) + (AVy * Py) + (AVz * Pz)\n",
        "\n",
        "                    # Success?\n",
        "                    if double_slantTolerance > double_p > -double_slantTolerance:\n",
        "                        int_success += 1\n",
        "\n",
        "                    if int_success > (int_points * 0.2):\n",
        "                        # Accept plane as A\n",
        "                        bool_accepted = True\n",
        "\n",
        "                        # Remember plane normal\n",
        "                        P = ((Px ** 2) + (Py ** 2) + (Pz ** 2)) ** 0.5\n",
        "                        PAx = Px / P\n",
        "                        PAy = Py / P\n",
        "                        PAz = Pz / P\n",
        "                        break\n",
        "\n",
        "                if bool_accepted:\n",
        "                    break\n",
        "\n",
        "            if bool_accepted:\n",
        "                break\n",
        "\n",
        "        # Points on the faces of cylinder\n",
        "        tot_Ax = 0\n",
        "        tot_Ay = 0\n",
        "        tot_Az = 0\n",
        "        tot_Wx = 0\n",
        "        tot_Wy = 0\n",
        "        tot_Wz = 0\n",
        "        int_Ap = 0\n",
        "        int_Wp = 0\n",
        "\n",
        "        # Cylinder Extrema\n",
        "        double_cylMaxX = Ax\n",
        "        double_cylMaxY = Ay\n",
        "        double_cylMaxZ = Az\n",
        "        double_cylMinX = Ax\n",
        "        double_cylMinY = Ay\n",
        "        double_cylMinZ = Az\n",
        "\n",
        "        for k in range(int_points):\n",
        "\n",
        "            # Identify coordinates\n",
        "            Bx = array_vertices[k, 0]\n",
        "            By = array_vertices[k, 1]\n",
        "            Bz = array_vertices[k, 2]\n",
        "\n",
        "            # Extrema Comparison\n",
        "            if Bx > double_cylMaxX:\n",
        "                double_cylMaxX = Bx\n",
        "            if By > double_cylMaxY:\n",
        "                double_cylMaxY = By\n",
        "            if Bz > double_cylMaxZ:\n",
        "                double_cylMaxZ = Bz\n",
        "            if Bx < double_cylMinX:\n",
        "                double_cylMinX = Bx\n",
        "            if By < double_cylMinY:\n",
        "                double_cylMinY = By\n",
        "            if Bz < double_cylMinZ:\n",
        "                double_cylMinZ = Bz\n",
        "\n",
        "            # Direction within plane\n",
        "            AVx = Bx - Ax\n",
        "            AVy = By - Ay\n",
        "            AVz = Bz - Az\n",
        "\n",
        "            # Plane equation\n",
        "            double_p = (AVx * PAx) + (AVy * PAy) + (AVz * PAz)\n",
        "\n",
        "            # Success?\n",
        "            if double_p > double_slantTolerance or double_p < -double_slantTolerance:\n",
        "\n",
        "                # Increase totals\n",
        "                tot_Wx += Bx\n",
        "                tot_Wy += By\n",
        "                tot_Wz += Bz\n",
        "                int_Wp += 1\n",
        "\n",
        "            else:\n",
        "\n",
        "                # Increase totals\n",
        "                tot_Ax += Bx\n",
        "                tot_Ay += By\n",
        "                tot_Az += Bz\n",
        "                int_Ap += 1\n",
        "\n",
        "        # Extrema Build, also shift coordinates to UV space\n",
        "        vector3_uvCylMax = Vector3(double_cylMaxX, double_cylMaxY, double_cylMaxZ).toUVSpace()\n",
        "        vector3_uvCylMin = Vector3(double_cylMinX, double_cylMinY, double_cylMinZ).toUVSpace()\n",
        "\n",
        "        # Top Plane Point\n",
        "        tot_Ax = tot_Ax / int_Ap\n",
        "        tot_Ay = tot_Ay / int_Ap\n",
        "        tot_Az = tot_Az / int_Ap\n",
        "        vector3_Atot = Vector3(tot_Ax, tot_Ay, tot_Az)\n",
        "\n",
        "        # Bot Plane Point\n",
        "        tot_Wx = tot_Wx / int_Wp\n",
        "        tot_Wy = tot_Wy / int_Wp\n",
        "        tot_Wz = tot_Wz / int_Wp\n",
        "        vector3_Wtot = Vector3(tot_Wx, tot_Wy, tot_Wz)\n",
        "\n",
        "        # Also used as radius of cylinder\n",
        "        double_rad = math.sqrt(((tot_Ax - Ax) ** 2) + ((tot_Ay - Ay) ** 2) + ((tot_Az - Az) ** 2))\n",
        "\n",
        "        # Find 3D Point to draw at\n",
        "\n",
        "        # Plane point, origin\n",
        "        O = vector3_Atot\n",
        "\n",
        "        # Distance along cylinder\n",
        "        tAWx = tot_Ax - tot_Wx\n",
        "        tAWy = tot_Ay - tot_Wy\n",
        "        tAWz = tot_Az - tot_Wz\n",
        "        double_OP = math.sqrt((tAWx ** 2) + (tAWy ** 2) + (tAWz ** 2))\n",
        "\n",
        "        # Plane Unit Vector Direction\n",
        "        Ox = PAx\n",
        "        Oy = PAy\n",
        "        Oz = PAz\n",
        "\n",
        "        # Another on Plane\n",
        "        Vx = Ax\n",
        "        Vy = Ay\n",
        "        Vz = Az\n",
        "\n",
        "        # OV directions\n",
        "        OVx = Vx - Ox\n",
        "        OVy = Vy - Oy\n",
        "        OVz = Vz - Oz\n",
        "        OV = math.sqrt((OVx ** 2) + (OVy ** 2) + (OVz ** 2))\n",
        "        OVx = OVx / OV\n",
        "        OVy = OVy / OV\n",
        "        OVz = OVz / OV\n",
        "\n",
        "        # Cross Product for the other direction vector\n",
        "        OWx = (OVy * Oz) - (OVz * Oy)\n",
        "        OWy = (OVz * Ox) - (OVx * Oz)\n",
        "        OWz = (OVx * Oy) - (OVy * Ox)\n",
        "\n",
        "        # Cross Product for correction\n",
        "        OVx = (Oy * OWz) - (Oz * OWy)\n",
        "        OVy = (Oz * OWx) - (Ox * OWz)\n",
        "        OVz = (Ox * OWy) - (Oy * OWx)\n",
        "\n",
        "        # Encapsulating Box\n",
        "        array_int_uvFace_boxIntercept = uvMap_map.corneredBoxFaces(vector3_uvCylMin, vector3_uvCylMax, double_tolerance)\n",
        "        int_mbx = len(array_int_uvFace_boxIntercept)\n",
        "\n",
        "        # Evaluate every face position in the cylinder\n",
        "        int_facesDrawn = 0\n",
        "        for faceIdx in range(int_mbx):\n",
        "\n",
        "            # Observed face\n",
        "            uvFace_observed = array_int_uvFace_boxIntercept[faceIdx, 1]\n",
        "            if not uvFace_observed:\n",
        "                continue\n",
        "\n",
        "            # Get vertices\n",
        "            vector3_A = uvFace_observed.vertices[0].v\n",
        "            vector3_B = uvFace_observed.vertices[1].v\n",
        "            vector3_C = uvFace_observed.vertices[2].v\n",
        "\n",
        "            # (un-convert from UV coordinates)\n",
        "            vector3_A = vector3_A.toSTLSpace()\n",
        "            vector3_B = vector3_B.toSTLSpace()\n",
        "            vector3_C = vector3_C.toSTLSpace()\n",
        "\n",
        "            # Obtain centroid\n",
        "            Px = (vector3_A.x + vector3_B.x + vector3_C.x) / 3.0\n",
        "            Py = (vector3_A.y + vector3_B.y + vector3_C.y) / 3.0\n",
        "            Pz = (vector3_A.z + vector3_B.z + vector3_C.z) / 3.0\n",
        "\n",
        "            # Reverse solving of the cylindrical coordinate equations\n",
        "            #\n",
        "            #   Note that these cylindrical coordinates are NOW assumed to\n",
        "            #   be aligned so that the Z axis is the axis of the cylinder,\n",
        "            #   thus double_z (distance along the axis of the cylinder) is\n",
        "            #   called 'double_z'\n",
        "            #\n",
        "            #   double_Px = (OWx * double_r * cos(double_phi)) + (OVx * double_r * sin(double_phi)) + (Ox * double_z) + O.x;\n",
        "            #   double_Py = (OWy * double_r * cos(double_phi)) + (OVy * double_r * sin(double_phi)) + (Oy * double_z) + O.y;\n",
        "            #   double_Pz = (OWz * double_r * cos(double_phi)) + (OVz * double_r * sin(double_phi)) + (Oz * double_z) + O.z;\n",
        "            #\n",
        "\n",
        "            # Calculations required for solving for PHI\n",
        "            double_den = ((Ox * (Py - O.y)) - (Oy * (Px - O.x)))\n",
        "            double_neg = -1 if double_den < 0 else 1\n",
        "            double_clef = ((Ox * (Pz - O.z)) - (Oz * (Px - O.x))) / (max(abs(double_den), 1E-7) * double_neg)\n",
        "            double_gamma = ((Ox * OWz) - (Oz * OWx))\n",
        "            double_delta = ((Ox * OVz) - (Oz * OVx))\n",
        "            double_psi = ((Ox * OWy) - (Oy * OWx))\n",
        "            double_theta = ((Ox * OVy) - (Oy * OVx))\n",
        "\n",
        "            if Ox == 0:\n",
        "                Ox = 0.00001\n",
        "            if Oy == 0:\n",
        "                Oy = 0.00001\n",
        "            if Oz == 0:\n",
        "                Oz = 0.00001\n",
        "\n",
        "            # Calculate PHI\n",
        "            double_phi = math.atan(\n",
        "                - (double_gamma - (double_clef * double_psi)) / (double_delta - (double_clef * double_theta)))\n",
        "\n",
        "            # Calculate R (now assuming that cylinders are oriented along the Z axis)\n",
        "            double_r = math.sqrt((Px - O.x) ** 2 + (Py - O.y) ** 2)\n",
        "            # = ((Ox * (Py - O.y)) - (Oy * (Px - O.x))) / (\n",
        "            #   (Ox * (OWy * math.cos(double_phi) + OVy * math.sin(double_phi))) - (\n",
        "            #   Oy * (OWx * math.cos(double_phi) + OVx * math.sin(double_phi))))\n",
        "\n",
        "            # Calculate Z (now assuming that cylinders are oriented along the Z axis)\n",
        "            double_z = Pz - O.z  # = ((Px - O.x) - (double_r * (OWx * math.cos(double_phi) + OVx * math.sin(double_phi)))) / Ox\n",
        "\n",
        "            # print('--| Px =', Px)\n",
        "            # print('--| Py =', Py)\n",
        "            # print('--| Pz =', Pz)\n",
        "            # print('--| r =', double_r)\n",
        "            # print('--| o =', double_phi)\n",
        "            # print('--| z =', double_z)\n",
        "\n",
        "            # Evaluate that the point is inside the cylinder\n",
        "            # oric_x = (OWx * double_r * math.cos(double_phi)) + (OVx * double_r * math.sin(double_phi)) + (Ox * double_z) + O.x\n",
        "            # oric_y = (OWy * double_r * math.cos(double_phi)) + (OVy * double_r * math.sin(double_phi)) + (Oy * double_z) + O.y\n",
        "            # oric_z = (OWz * double_r * math.cos(double_phi)) + (OVz * double_r * math.sin(double_phi)) + (Oz * double_z) + O.z\n",
        "\n",
        "            # print('--| Px =', Px)\n",
        "            # print('--| Py =', Py)\n",
        "            # print('--| Pz =', Pz)\n",
        "            # print('--| dx =', Px-oric_x)\n",
        "            # print('--| dy =', Py-oric_y)\n",
        "            # print('--| dz =', Pz-oric_z)\n",
        "            # print('--| z =', double_z)\n",
        "            # print('--| r =', double_r)\n",
        "\n",
        "            if math.isnan(double_z) or double_z < (double_OP * -0.1) or double_z > double_OP:\n",
        "                continue\n",
        "\n",
        "            if math.isnan(double_r) or (double_r * 0.930618) > double_rad or (double_r * 0.930618) < -double_rad:\n",
        "                # print('Face #', faceIdx, ', R Error, r =', double_r, '/', double_rad)\n",
        "                continue\n",
        "\n",
        "            # print('Face #', faceIdx, ', Good, r =', double_r, ', z =', double_z)\n",
        "\n",
        "            # Color of marking\n",
        "            int_r = 0\n",
        "            int_g = 0\n",
        "            int_b = 255\n",
        "\n",
        "            # Draw point onto texture\n",
        "            rgbImage_input = fillFace(rgbImage_input, rows, columns, uvFace_observed, int_r, int_g, int_b)\n",
        "\n",
        "            int_facesDrawn += 1\n",
        "            if int_facesDrawn % 300 == 0:\n",
        "                print(f'Drew face #{uvFace_observed.index} ({faceIdx}/{int_mbx}), total {int_facesDrawn} faces drawn')\n",
        "\n",
        "    # Result\n",
        "    return rgbImage_input"
      ],
      "metadata": {
        "id": "m_tjl5JhY75r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actually generating the texture PNG file"
      ],
      "metadata": {
        "id": "kmp3jmIuZC4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Important File Paths"
      ],
      "metadata": {
        "id": "ooHwq5PDciz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Texture files for each of the regions:"
      ],
      "metadata": {
        "id": "21haS0Vmcbax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "str_surface_texture_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "C7DWxjroco54",
        "outputId": "0e72407a-73f9-4caf-efab-dce2916c94d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f197a731-0797-45cd-8264-1654d546aef5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f197a731-0797-45cd-8264-1654d546aef5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A3.png to A3.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "str_feeders_texture_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "sZCxQ0g9css7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b58593d5-0abb-4c86-9467-93e18a3317d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6c03e538-acb8-407e-af00-04bb7d0c3b89\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6c03e538-acb8-407e-af00-04bb7d0c3b89\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving welding.png to welding.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result file paths"
      ],
      "metadata": {
        "id": "kGL2q6yeb2br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mark with blue, red, and black colors\n",
        "str_mark_result_path = 'result_mark.png'\n",
        "\n",
        "# Actual texture\n",
        "str_feeders_result_path = 'result_tex.png'"
      ],
      "metadata": {
        "id": "GIxdGrVAZvjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input File Paths"
      ],
      "metadata": {
        "id": "IbpnKQQBb5UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input uv map file path (.obj)\n",
        "str_obj_path = '/content/remeshed_uv.obj'\n",
        "\n",
        "# Input feeder file paths (.stl)\n",
        "array_str_feeder_paths = np.empty([0])\n",
        "for i in range(0, num_arrays):\n",
        "    array_str_feeder_paths = np.append(array_str_feeder_paths, f'/content/feeder{i}.stl')"
      ],
      "metadata": {
        "id": "oHeMif5gb8A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More parameters\n",
        "Generating a 2D texture from features in 3D coordinates is somewhat complicated, so some tolerances must be set."
      ],
      "metadata": {
        "id": "gNlf_8eveEkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PNG Texture Result Parameters"
      ],
      "metadata": {
        "id": "Ky5eNe3De3iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dimensions of output texture\n",
        "int_image_rows = 1024\n",
        "int_image_columns = 1024\n",
        "\n",
        "# Create image of the dimensions specified, paint it black in its entirety\n",
        "rgbImage = np.empty((int_image_rows, int_image_columns, 3), dtype=np.uint8)\n",
        "for x in range(int_image_columns):\n",
        "    for y in range(int_image_rows):\n",
        "        rgbImage[y, x, 0] = 0\n",
        "        rgbImage[y, x, 1] = 0\n",
        "        rgbImage[y, x, 2] = 0\n",
        "cv2.imwrite('/content/unfinished_mark.png', rgbImage)"
      ],
      "metadata": {
        "id": "St0-L-U7e6Tk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba09d51c-0293-4663-e635-86e837a5de8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STL Feeder Parameters"
      ],
      "metadata": {
        "id": "HCWdn7treluZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feeder Geometry Tolerance\n",
        "double_feeder_tolerance = 0\n",
        "\n",
        "# Resolution of shape\n",
        "double_feeders_resolution = 1"
      ],
      "metadata": {
        "id": "lfhVDS_8eupL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mark Geometry\n",
        "Make markings in a 2D-texture based on 3D features"
      ],
      "metadata": {
        "id": "5pBqr24zihUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print('---->   Reading OBJ   <----')\n",
        "uv_map = readOBJFile(str_obj_path)\n",
        "\n",
        "#print('---->   Drawing Feeders   <----')\n",
        "rgbImage_mark = drawCylinder(array_str_feeder_paths, uv_map, rgbImage, int_image_rows, int_image_columns, double_feeder_tolerance)\n",
        "\n",
        "#print('Saving mark result...')\n",
        "cv2.imwrite(str_mark_result_path, rgbImage_mark)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aGQ-1SJiY03",
        "outputId": "4c2642b5-5d24-4b63-a29e-80ada1b5adeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading Face #0 of #189820\n",
            "Reading Face #300 of #189820\n",
            "Reading Face #600 of #189820\n",
            "Reading Face #900 of #189820\n",
            "Reading Face #1200 of #189820\n",
            "Reading Face #1500 of #189820\n",
            "Reading Face #1800 of #189820\n",
            "Reading Face #2100 of #189820\n",
            "Reading Face #2400 of #189820\n",
            "Reading Face #2700 of #189820\n",
            "Reading Face #3000 of #189820\n",
            "Reading Face #3300 of #189820\n",
            "Reading Face #3600 of #189820\n",
            "Reading Face #3900 of #189820\n",
            "Reading Face #4200 of #189820\n",
            "Reading Face #4500 of #189820\n",
            "Reading Face #4800 of #189820\n",
            "Reading Face #5100 of #189820\n",
            "Reading Face #5400 of #189820\n",
            "Reading Face #5700 of #189820\n",
            "Reading Face #6000 of #189820\n",
            "Reading Face #6300 of #189820\n",
            "Reading Face #6600 of #189820\n",
            "Reading Face #6900 of #189820\n",
            "Reading Face #7200 of #189820\n",
            "Reading Face #7500 of #189820\n",
            "Reading Face #7800 of #189820\n",
            "Reading Face #8100 of #189820\n",
            "Reading Face #8400 of #189820\n",
            "Reading Face #8700 of #189820\n",
            "Reading Face #9000 of #189820\n",
            "Reading Face #9300 of #189820\n",
            "Reading Face #9600 of #189820\n",
            "Reading Face #9900 of #189820\n",
            "Reading Face #10200 of #189820\n",
            "Reading Face #10500 of #189820\n",
            "Reading Face #10800 of #189820\n",
            "Reading Face #11100 of #189820\n",
            "Reading Face #11400 of #189820\n",
            "Reading Face #11700 of #189820\n",
            "Reading Face #12000 of #189820\n",
            "Reading Face #12300 of #189820\n",
            "Reading Face #12600 of #189820\n",
            "Reading Face #12900 of #189820\n",
            "Reading Face #13200 of #189820\n",
            "Reading Face #13500 of #189820\n",
            "Reading Face #13800 of #189820\n",
            "Reading Face #14100 of #189820\n",
            "Reading Face #14400 of #189820\n",
            "Reading Face #14700 of #189820\n",
            "Reading Face #15000 of #189820\n",
            "Reading Face #15300 of #189820\n",
            "Reading Face #15600 of #189820\n",
            "Reading Face #15900 of #189820\n",
            "Reading Face #16200 of #189820\n",
            "Reading Face #16500 of #189820\n",
            "Reading Face #16800 of #189820\n",
            "Reading Face #17100 of #189820\n",
            "Reading Face #17400 of #189820\n",
            "Reading Face #17700 of #189820\n",
            "Reading Face #18000 of #189820\n",
            "Reading Face #18300 of #189820\n",
            "Reading Face #18600 of #189820\n",
            "Reading Face #18900 of #189820\n",
            "Reading Face #19200 of #189820\n",
            "Reading Face #19500 of #189820\n",
            "Reading Face #19800 of #189820\n",
            "Reading Face #20100 of #189820\n",
            "Reading Face #20400 of #189820\n",
            "Reading Face #20700 of #189820\n",
            "Reading Face #21000 of #189820\n",
            "Reading Face #21300 of #189820\n",
            "Reading Face #21600 of #189820\n",
            "Reading Face #21900 of #189820\n",
            "Reading Face #22200 of #189820\n",
            "Reading Face #22500 of #189820\n",
            "Reading Face #22800 of #189820\n",
            "Reading Face #23100 of #189820\n",
            "Reading Face #23400 of #189820\n",
            "Reading Face #23700 of #189820\n",
            "Reading Face #24000 of #189820\n",
            "Reading Face #24300 of #189820\n",
            "Reading Face #24600 of #189820\n",
            "Reading Face #24900 of #189820\n",
            "Reading Face #25200 of #189820\n",
            "Reading Face #25500 of #189820\n",
            "Reading Face #25800 of #189820\n",
            "Reading Face #26100 of #189820\n",
            "Reading Face #26400 of #189820\n",
            "Reading Face #26700 of #189820\n",
            "Reading Face #27000 of #189820\n",
            "Reading Face #27300 of #189820\n",
            "Reading Face #27600 of #189820\n",
            "Reading Face #27900 of #189820\n",
            "Reading Face #28200 of #189820\n",
            "Reading Face #28500 of #189820\n",
            "Reading Face #28800 of #189820\n",
            "Reading Face #29100 of #189820\n",
            "Reading Face #29400 of #189820\n",
            "Reading Face #29700 of #189820\n",
            "Reading Face #30000 of #189820\n",
            "Reading Face #30300 of #189820\n",
            "Reading Face #30600 of #189820\n",
            "Reading Face #30900 of #189820\n",
            "Reading Face #31200 of #189820\n",
            "Reading Face #31500 of #189820\n",
            "Reading Face #31800 of #189820\n",
            "Reading Face #32100 of #189820\n",
            "Reading Face #32400 of #189820\n",
            "Reading Face #32700 of #189820\n",
            "Reading Face #33000 of #189820\n",
            "Reading Face #33300 of #189820\n",
            "Reading Face #33600 of #189820\n",
            "Reading Face #33900 of #189820\n",
            "Reading Face #34200 of #189820\n",
            "Reading Face #34500 of #189820\n",
            "Reading Face #34800 of #189820\n",
            "Reading Face #35100 of #189820\n",
            "Reading Face #35400 of #189820\n",
            "Reading Face #35700 of #189820\n",
            "Reading Face #36000 of #189820\n",
            "Reading Face #36300 of #189820\n",
            "Reading Face #36600 of #189820\n",
            "Reading Face #36900 of #189820\n",
            "Reading Face #37200 of #189820\n",
            "Reading Face #37500 of #189820\n",
            "Reading Face #37800 of #189820\n",
            "Reading Face #38100 of #189820\n",
            "Reading Face #38400 of #189820\n",
            "Reading Face #38700 of #189820\n",
            "Reading Face #39000 of #189820\n",
            "Reading Face #39300 of #189820\n",
            "Reading Face #39600 of #189820\n",
            "Reading Face #39900 of #189820\n",
            "Reading Face #40200 of #189820\n",
            "Reading Face #40500 of #189820\n",
            "Reading Face #40800 of #189820\n",
            "Reading Face #41100 of #189820\n",
            "Reading Face #41400 of #189820\n",
            "Reading Face #41700 of #189820\n",
            "Reading Face #42000 of #189820\n",
            "Reading Face #42300 of #189820\n",
            "Reading Face #42600 of #189820\n",
            "Reading Face #42900 of #189820\n",
            "Reading Face #43200 of #189820\n",
            "Reading Face #43500 of #189820\n",
            "Reading Face #43800 of #189820\n",
            "Reading Face #44100 of #189820\n",
            "Reading Face #44400 of #189820\n",
            "Reading Face #44700 of #189820\n",
            "Reading Face #45000 of #189820\n",
            "Reading Face #45300 of #189820\n",
            "Reading Face #45600 of #189820\n",
            "Reading Face #45900 of #189820\n",
            "Reading Face #46200 of #189820\n",
            "Reading Face #46500 of #189820\n",
            "Reading Face #46800 of #189820\n",
            "Reading Face #47100 of #189820\n",
            "Reading Face #47400 of #189820\n",
            "Reading Face #47700 of #189820\n",
            "Reading Face #48000 of #189820\n",
            "Reading Face #48300 of #189820\n",
            "Reading Face #48600 of #189820\n",
            "Reading Face #48900 of #189820\n",
            "Reading Face #49200 of #189820\n",
            "Reading Face #49500 of #189820\n",
            "Reading Face #49800 of #189820\n",
            "Reading Face #50100 of #189820\n",
            "Reading Face #50400 of #189820\n",
            "Reading Face #50700 of #189820\n",
            "Reading Face #51000 of #189820\n",
            "Reading Face #51300 of #189820\n",
            "Reading Face #51600 of #189820\n",
            "Reading Face #51900 of #189820\n",
            "Reading Face #52200 of #189820\n",
            "Reading Face #52500 of #189820\n",
            "Reading Face #52800 of #189820\n",
            "Reading Face #53100 of #189820\n",
            "Reading Face #53400 of #189820\n",
            "Reading Face #53700 of #189820\n",
            "Reading Face #54000 of #189820\n",
            "Reading Face #54300 of #189820\n",
            "Reading Face #54600 of #189820\n",
            "Reading Face #54900 of #189820\n",
            "Reading Face #55200 of #189820\n",
            "Reading Face #55500 of #189820\n",
            "Reading Face #55800 of #189820\n",
            "Reading Face #56100 of #189820\n",
            "Reading Face #56400 of #189820\n",
            "Reading Face #56700 of #189820\n",
            "Reading Face #57000 of #189820\n",
            "Reading Face #57300 of #189820\n",
            "Reading Face #57600 of #189820\n",
            "Reading Face #57900 of #189820\n",
            "Reading Face #58200 of #189820\n",
            "Reading Face #58500 of #189820\n",
            "Reading Face #58800 of #189820\n",
            "Reading Face #59100 of #189820\n",
            "Reading Face #59400 of #189820\n",
            "Reading Face #59700 of #189820\n",
            "Reading Face #60000 of #189820\n",
            "Reading Face #60300 of #189820\n",
            "Reading Face #60600 of #189820\n",
            "Reading Face #60900 of #189820\n",
            "Reading Face #61200 of #189820\n",
            "Reading Face #61500 of #189820\n",
            "Reading Face #61800 of #189820\n",
            "Reading Face #62100 of #189820\n",
            "Reading Face #62400 of #189820\n",
            "Reading Face #62700 of #189820\n",
            "Reading Face #63000 of #189820\n",
            "Reading Face #63300 of #189820\n",
            "Reading Face #63600 of #189820\n",
            "Reading Face #63900 of #189820\n",
            "Reading Face #64200 of #189820\n",
            "Reading Face #64500 of #189820\n",
            "Reading Face #64800 of #189820\n",
            "Reading Face #65100 of #189820\n",
            "Reading Face #65400 of #189820\n",
            "Reading Face #65700 of #189820\n",
            "Reading Face #66000 of #189820\n",
            "Reading Face #66300 of #189820\n",
            "Reading Face #66600 of #189820\n",
            "Reading Face #66900 of #189820\n",
            "Reading Face #67200 of #189820\n",
            "Reading Face #67500 of #189820\n",
            "Reading Face #67800 of #189820\n",
            "Reading Face #68100 of #189820\n",
            "Reading Face #68400 of #189820\n",
            "Reading Face #68700 of #189820\n",
            "Reading Face #69000 of #189820\n",
            "Reading Face #69300 of #189820\n",
            "Reading Face #69600 of #189820\n",
            "Reading Face #69900 of #189820\n",
            "Reading Face #70200 of #189820\n",
            "Reading Face #70500 of #189820\n",
            "Reading Face #70800 of #189820\n",
            "Reading Face #71100 of #189820\n",
            "Reading Face #71400 of #189820\n",
            "Reading Face #71700 of #189820\n",
            "Reading Face #72000 of #189820\n",
            "Reading Face #72300 of #189820\n",
            "Reading Face #72600 of #189820\n",
            "Reading Face #72900 of #189820\n",
            "Reading Face #73200 of #189820\n",
            "Reading Face #73500 of #189820\n",
            "Reading Face #73800 of #189820\n",
            "Reading Face #74100 of #189820\n",
            "Reading Face #74400 of #189820\n",
            "Reading Face #74700 of #189820\n",
            "Reading Face #75000 of #189820\n",
            "Reading Face #75300 of #189820\n",
            "Reading Face #75600 of #189820\n",
            "Reading Face #75900 of #189820\n",
            "Reading Face #76200 of #189820\n",
            "Reading Face #76500 of #189820\n",
            "Reading Face #76800 of #189820\n",
            "Reading Face #77100 of #189820\n",
            "Reading Face #77400 of #189820\n",
            "Reading Face #77700 of #189820\n",
            "Reading Face #78000 of #189820\n",
            "Reading Face #78300 of #189820\n",
            "Reading Face #78600 of #189820\n",
            "Reading Face #78900 of #189820\n",
            "Reading Face #79200 of #189820\n",
            "Reading Face #79500 of #189820\n",
            "Reading Face #79800 of #189820\n",
            "Reading Face #80100 of #189820\n",
            "Reading Face #80400 of #189820\n",
            "Reading Face #80700 of #189820\n",
            "Reading Face #81000 of #189820\n",
            "Reading Face #81300 of #189820\n",
            "Reading Face #81600 of #189820\n",
            "Reading Face #81900 of #189820\n",
            "Reading Face #82200 of #189820\n",
            "Reading Face #82500 of #189820\n",
            "Reading Face #82800 of #189820\n",
            "Reading Face #83100 of #189820\n",
            "Reading Face #83400 of #189820\n",
            "Reading Face #83700 of #189820\n",
            "Reading Face #84000 of #189820\n",
            "Reading Face #84300 of #189820\n",
            "Reading Face #84600 of #189820\n",
            "Reading Face #84900 of #189820\n",
            "Reading Face #85200 of #189820\n",
            "Reading Face #85500 of #189820\n",
            "Reading Face #85800 of #189820\n",
            "Reading Face #86100 of #189820\n",
            "Reading Face #86400 of #189820\n",
            "Reading Face #86700 of #189820\n",
            "Reading Face #87000 of #189820\n",
            "Reading Face #87300 of #189820\n",
            "Reading Face #87600 of #189820\n",
            "Reading Face #87900 of #189820\n",
            "Reading Face #88200 of #189820\n",
            "Reading Face #88500 of #189820\n",
            "Reading Face #88800 of #189820\n",
            "Reading Face #89100 of #189820\n",
            "Reading Face #89400 of #189820\n",
            "Reading Face #89700 of #189820\n",
            "Reading Face #90000 of #189820\n",
            "Reading Face #90300 of #189820\n",
            "Reading Face #90600 of #189820\n",
            "Reading Face #90900 of #189820\n",
            "Reading Face #91200 of #189820\n",
            "Reading Face #91500 of #189820\n",
            "Reading Face #91800 of #189820\n",
            "Reading Face #92100 of #189820\n",
            "Reading Face #92400 of #189820\n",
            "Reading Face #92700 of #189820\n",
            "Reading Face #93000 of #189820\n",
            "Reading Face #93300 of #189820\n",
            "Reading Face #93600 of #189820\n",
            "Reading Face #93900 of #189820\n",
            "Reading Face #94200 of #189820\n",
            "Reading Face #94500 of #189820\n",
            "Reading Face #94800 of #189820\n",
            "Reading Face #95100 of #189820\n",
            "Reading Face #95400 of #189820\n",
            "Reading Face #95700 of #189820\n",
            "Reading Face #96000 of #189820\n",
            "Reading Face #96300 of #189820\n",
            "Reading Face #96600 of #189820\n",
            "Reading Face #96900 of #189820\n",
            "Reading Face #97200 of #189820\n",
            "Reading Face #97500 of #189820\n",
            "Reading Face #97800 of #189820\n",
            "Reading Face #98100 of #189820\n",
            "Reading Face #98400 of #189820\n",
            "Reading Face #98700 of #189820\n",
            "Reading Face #99000 of #189820\n",
            "Reading Face #99300 of #189820\n",
            "Reading Face #99600 of #189820\n",
            "Reading Face #99900 of #189820\n",
            "Reading Face #100200 of #189820\n",
            "Reading Face #100500 of #189820\n",
            "Reading Face #100800 of #189820\n",
            "Reading Face #101100 of #189820\n",
            "Reading Face #101400 of #189820\n",
            "Reading Face #101700 of #189820\n",
            "Reading Face #102000 of #189820\n",
            "Reading Face #102300 of #189820\n",
            "Reading Face #102600 of #189820\n",
            "Reading Face #102900 of #189820\n",
            "Reading Face #103200 of #189820\n",
            "Reading Face #103500 of #189820\n",
            "Reading Face #103800 of #189820\n",
            "Reading Face #104100 of #189820\n",
            "Reading Face #104400 of #189820\n",
            "Reading Face #104700 of #189820\n",
            "Reading Face #105000 of #189820\n",
            "Reading Face #105300 of #189820\n",
            "Reading Face #105600 of #189820\n",
            "Reading Face #105900 of #189820\n",
            "Reading Face #106200 of #189820\n",
            "Reading Face #106500 of #189820\n",
            "Reading Face #106800 of #189820\n",
            "Reading Face #107100 of #189820\n",
            "Reading Face #107400 of #189820\n",
            "Reading Face #107700 of #189820\n",
            "Reading Face #108000 of #189820\n",
            "Reading Face #108300 of #189820\n",
            "Reading Face #108600 of #189820\n",
            "Reading Face #108900 of #189820\n",
            "Reading Face #109200 of #189820\n",
            "Reading Face #109500 of #189820\n",
            "Reading Face #109800 of #189820\n",
            "Reading Face #110100 of #189820\n",
            "Reading Face #110400 of #189820\n",
            "Reading Face #110700 of #189820\n",
            "Reading Face #111000 of #189820\n",
            "Reading Face #111300 of #189820\n",
            "Reading Face #111600 of #189820\n",
            "Reading Face #111900 of #189820\n",
            "Reading Face #112200 of #189820\n",
            "Reading Face #112500 of #189820\n",
            "Reading Face #112800 of #189820\n",
            "Reading Face #113100 of #189820\n",
            "Reading Face #113400 of #189820\n",
            "Reading Face #113700 of #189820\n",
            "Reading Face #114000 of #189820\n",
            "Reading Face #114300 of #189820\n",
            "Reading Face #114600 of #189820\n",
            "Reading Face #114900 of #189820\n",
            "Reading Face #115200 of #189820\n",
            "Reading Face #115500 of #189820\n",
            "Reading Face #115800 of #189820\n",
            "Reading Face #116100 of #189820\n",
            "Reading Face #116400 of #189820\n",
            "Reading Face #116700 of #189820\n",
            "Reading Face #117000 of #189820\n",
            "Reading Face #117300 of #189820\n",
            "Reading Face #117600 of #189820\n",
            "Reading Face #117900 of #189820\n",
            "Reading Face #118200 of #189820\n",
            "Reading Face #118500 of #189820\n",
            "Reading Face #118800 of #189820\n",
            "Reading Face #119100 of #189820\n",
            "Reading Face #119400 of #189820\n",
            "Reading Face #119700 of #189820\n",
            "Reading Face #120000 of #189820\n",
            "Reading Face #120300 of #189820\n",
            "Reading Face #120600 of #189820\n",
            "Reading Face #120900 of #189820\n",
            "Reading Face #121200 of #189820\n",
            "Reading Face #121500 of #189820\n",
            "Reading Face #121800 of #189820\n",
            "Reading Face #122100 of #189820\n",
            "Reading Face #122400 of #189820\n",
            "Reading Face #122700 of #189820\n",
            "Reading Face #123000 of #189820\n",
            "Reading Face #123300 of #189820\n",
            "Reading Face #123600 of #189820\n",
            "Reading Face #123900 of #189820\n",
            "Reading Face #124200 of #189820\n",
            "Reading Face #124500 of #189820\n",
            "Reading Face #124800 of #189820\n",
            "Reading Face #125100 of #189820\n",
            "Reading Face #125400 of #189820\n",
            "Reading Face #125700 of #189820\n",
            "Reading Face #126000 of #189820\n",
            "Reading Face #126300 of #189820\n",
            "Reading Face #126600 of #189820\n",
            "Reading Face #126900 of #189820\n",
            "Reading Face #127200 of #189820\n",
            "Reading Face #127500 of #189820\n",
            "Reading Face #127800 of #189820\n",
            "Reading Face #128100 of #189820\n",
            "Reading Face #128400 of #189820\n",
            "Reading Face #128700 of #189820\n",
            "Reading Face #129000 of #189820\n",
            "Reading Face #129300 of #189820\n",
            "Reading Face #129600 of #189820\n",
            "Reading Face #129900 of #189820\n",
            "Reading Face #130200 of #189820\n",
            "Reading Face #130500 of #189820\n",
            "Reading Face #130800 of #189820\n",
            "Reading Face #131100 of #189820\n",
            "Reading Face #131400 of #189820\n",
            "Reading Face #131700 of #189820\n",
            "Reading Face #132000 of #189820\n",
            "Reading Face #132300 of #189820\n",
            "Reading Face #132600 of #189820\n",
            "Reading Face #132900 of #189820\n",
            "Reading Face #133200 of #189820\n",
            "Reading Face #133500 of #189820\n",
            "Reading Face #133800 of #189820\n",
            "Reading Face #134100 of #189820\n",
            "Reading Face #134400 of #189820\n",
            "Reading Face #134700 of #189820\n",
            "Reading Face #135000 of #189820\n",
            "Reading Face #135300 of #189820\n",
            "Reading Face #135600 of #189820\n",
            "Reading Face #135900 of #189820\n",
            "Reading Face #136200 of #189820\n",
            "Reading Face #136500 of #189820\n",
            "Reading Face #136800 of #189820\n",
            "Reading Face #137100 of #189820\n",
            "Reading Face #137400 of #189820\n",
            "Reading Face #137700 of #189820\n",
            "Reading Face #138000 of #189820\n",
            "Reading Face #138300 of #189820\n",
            "Reading Face #138600 of #189820\n",
            "Reading Face #138900 of #189820\n",
            "Reading Face #139200 of #189820\n",
            "Reading Face #139500 of #189820\n",
            "Reading Face #139800 of #189820\n",
            "Reading Face #140100 of #189820\n",
            "Reading Face #140400 of #189820\n",
            "Reading Face #140700 of #189820\n",
            "Reading Face #141000 of #189820\n",
            "Reading Face #141300 of #189820\n",
            "Reading Face #141600 of #189820\n",
            "Reading Face #141900 of #189820\n",
            "Reading Face #142200 of #189820\n",
            "Reading Face #142500 of #189820\n",
            "Reading Face #142800 of #189820\n",
            "Reading Face #143100 of #189820\n",
            "Reading Face #143400 of #189820\n",
            "Reading Face #143700 of #189820\n",
            "Reading Face #144000 of #189820\n",
            "Reading Face #144300 of #189820\n",
            "Reading Face #144600 of #189820\n",
            "Reading Face #144900 of #189820\n",
            "Reading Face #145200 of #189820\n",
            "Reading Face #145500 of #189820\n",
            "Reading Face #145800 of #189820\n",
            "Reading Face #146100 of #189820\n",
            "Reading Face #146400 of #189820\n",
            "Reading Face #146700 of #189820\n",
            "Reading Face #147000 of #189820\n",
            "Reading Face #147300 of #189820\n",
            "Reading Face #147600 of #189820\n",
            "Reading Face #147900 of #189820\n",
            "Reading Face #148200 of #189820\n",
            "Reading Face #148500 of #189820\n",
            "Reading Face #148800 of #189820\n",
            "Reading Face #149100 of #189820\n",
            "Reading Face #149400 of #189820\n",
            "Reading Face #149700 of #189820\n",
            "Reading Face #150000 of #189820\n",
            "Reading Face #150300 of #189820\n",
            "Reading Face #150600 of #189820\n",
            "Reading Face #150900 of #189820\n",
            "Reading Face #151200 of #189820\n",
            "Reading Face #151500 of #189820\n",
            "Reading Face #151800 of #189820\n",
            "Reading Face #152100 of #189820\n",
            "Reading Face #152400 of #189820\n",
            "Reading Face #152700 of #189820\n",
            "Reading Face #153000 of #189820\n",
            "Reading Face #153300 of #189820\n",
            "Reading Face #153600 of #189820\n",
            "Reading Face #153900 of #189820\n",
            "Reading Face #154200 of #189820\n",
            "Reading Face #154500 of #189820\n",
            "Reading Face #154800 of #189820\n",
            "Reading Face #155100 of #189820\n",
            "Reading Face #155400 of #189820\n",
            "Reading Face #155700 of #189820\n",
            "Reading Face #156000 of #189820\n",
            "Reading Face #156300 of #189820\n",
            "Reading Face #156600 of #189820\n",
            "Reading Face #156900 of #189820\n",
            "Reading Face #157200 of #189820\n",
            "Reading Face #157500 of #189820\n",
            "Reading Face #157800 of #189820\n",
            "Reading Face #158100 of #189820\n",
            "Reading Face #158400 of #189820\n",
            "Reading Face #158700 of #189820\n",
            "Reading Face #159000 of #189820\n",
            "Reading Face #159300 of #189820\n",
            "Reading Face #159600 of #189820\n",
            "Reading Face #159900 of #189820\n",
            "Reading Face #160200 of #189820\n",
            "Reading Face #160500 of #189820\n",
            "Reading Face #160800 of #189820\n",
            "Reading Face #161100 of #189820\n",
            "Reading Face #161400 of #189820\n",
            "Reading Face #161700 of #189820\n",
            "Reading Face #162000 of #189820\n",
            "Reading Face #162300 of #189820\n",
            "Reading Face #162600 of #189820\n",
            "Reading Face #162900 of #189820\n",
            "Reading Face #163200 of #189820\n",
            "Reading Face #163500 of #189820\n",
            "Reading Face #163800 of #189820\n",
            "Reading Face #164100 of #189820\n",
            "Reading Face #164400 of #189820\n",
            "Reading Face #164700 of #189820\n",
            "Reading Face #165000 of #189820\n",
            "Reading Face #165300 of #189820\n",
            "Reading Face #165600 of #189820\n",
            "Reading Face #165900 of #189820\n",
            "Reading Face #166200 of #189820\n",
            "Reading Face #166500 of #189820\n",
            "Reading Face #166800 of #189820\n",
            "Reading Face #167100 of #189820\n",
            "Reading Face #167400 of #189820\n",
            "Reading Face #167700 of #189820\n",
            "Reading Face #168000 of #189820\n",
            "Reading Face #168300 of #189820\n",
            "Reading Face #168600 of #189820\n",
            "Reading Face #168900 of #189820\n",
            "Reading Face #169200 of #189820\n",
            "Reading Face #169500 of #189820\n",
            "Reading Face #169800 of #189820\n",
            "Reading Face #170100 of #189820\n",
            "Reading Face #170400 of #189820\n",
            "Reading Face #170700 of #189820\n",
            "Reading Face #171000 of #189820\n",
            "Reading Face #171300 of #189820\n",
            "Reading Face #171600 of #189820\n",
            "Reading Face #171900 of #189820\n",
            "Reading Face #172200 of #189820\n",
            "Reading Face #172500 of #189820\n",
            "Reading Face #172800 of #189820\n",
            "Reading Face #173100 of #189820\n",
            "Reading Face #173400 of #189820\n",
            "Reading Face #173700 of #189820\n",
            "Reading Face #174000 of #189820\n",
            "Reading Face #174300 of #189820\n",
            "Reading Face #174600 of #189820\n",
            "Reading Face #174900 of #189820\n",
            "Reading Face #175200 of #189820\n",
            "Reading Face #175500 of #189820\n",
            "Reading Face #175800 of #189820\n",
            "Reading Face #176100 of #189820\n",
            "Reading Face #176400 of #189820\n",
            "Reading Face #176700 of #189820\n",
            "Reading Face #177000 of #189820\n",
            "Reading Face #177300 of #189820\n",
            "Reading Face #177600 of #189820\n",
            "Reading Face #177900 of #189820\n",
            "Reading Face #178200 of #189820\n",
            "Reading Face #178500 of #189820\n",
            "Reading Face #178800 of #189820\n",
            "Reading Face #179100 of #189820\n",
            "Reading Face #179400 of #189820\n",
            "Reading Face #179700 of #189820\n",
            "Reading Face #180000 of #189820\n",
            "Reading Face #180300 of #189820\n",
            "Reading Face #180600 of #189820\n",
            "Reading Face #180900 of #189820\n",
            "Reading Face #181200 of #189820\n",
            "Reading Face #181500 of #189820\n",
            "Reading Face #181800 of #189820\n",
            "Reading Face #182100 of #189820\n",
            "Reading Face #182400 of #189820\n",
            "Reading Face #182700 of #189820\n",
            "Reading Face #183000 of #189820\n",
            "Reading Face #183300 of #189820\n",
            "Reading Face #183600 of #189820\n",
            "Reading Face #183900 of #189820\n",
            "Reading Face #184200 of #189820\n",
            "Reading Face #184500 of #189820\n",
            "Reading Face #184800 of #189820\n",
            "Reading Face #185100 of #189820\n",
            "Reading Face #185400 of #189820\n",
            "Reading Face #185700 of #189820\n",
            "Reading Face #186000 of #189820\n",
            "Reading Face #186300 of #189820\n",
            "Reading Face #186600 of #189820\n",
            "Reading Face #186900 of #189820\n",
            "Reading Face #187200 of #189820\n",
            "Reading Face #187500 of #189820\n",
            "Reading Face #187800 of #189820\n",
            "Reading Face #188100 of #189820\n",
            "Reading Face #188400 of #189820\n",
            "Reading Face #188700 of #189820\n",
            "Reading Face #189000 of #189820\n",
            "Reading Face #189300 of #189820\n",
            "Reading Face #189600 of #189820\n",
            "Drawing Riser #1\n",
            "Cornered Box Faces 3960/189820\n",
            "Drew face #42695 (429/3960), total 300 faces drawn\n",
            "Drew face #43785 (751/3960), total 600 faces drawn\n",
            "Drew face #62297 (1052/3960), total 900 faces drawn\n",
            "Drew face #63367 (1354/3960), total 1200 faces drawn\n",
            "Drew face #63693 (1677/3960), total 1500 faces drawn\n",
            "Drew face #136618 (2200/3960), total 1800 faces drawn\n",
            "Drew face #137757 (2561/3960), total 2100 faces drawn\n",
            "Drew face #138848 (2884/3960), total 2400 faces drawn\n",
            "Drew face #157360 (3185/3960), total 2700 faces drawn\n",
            "Drew face #158451 (3508/3960), total 3000 faces drawn\n",
            "Drew face #159663 (3888/3960), total 3300 faces drawn\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recolor Texture\n",
        "The new texture has been marked, just copy the pixels off the input texture files onto it, replacing these marks."
      ],
      "metadata": {
        "id": "n8onRLmMialu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resolution of .png textures\n",
        "double_mark_resolution = uv_map.average_resolution(int_image_rows, int_image_columns, 10000)\n",
        "print(f'OBJ Resolution = {double_mark_resolution}')\n",
        "\n",
        "rgbImage_result = rgbImage_mark\n",
        "\n",
        "# Resolutions (pixels per millimeter)\n",
        "#\n",
        "# The Texture Resolution:\n",
        "#     Resolution of the textures that will be copied onto the result\n",
        "#\n",
        "# The Result Resolution:\n",
        "#     Resolution of the output file from the OBJ calculations that\n",
        "#     draw in red and blue the parting and feeders of the casting.\n",
        "double_texScale = 3.3 / math.sqrt(double_mark_resolution)\n",
        "double_risScale = 0.1 / math.sqrt(double_mark_resolution)\n",
        "\n",
        "print('---->   Generating Texture   <----')\n",
        "rgbImage_plainTex = betterImRead(str_surface_texture_path, True)\n",
        "rgbImage_feederTex = betterImRead(str_feeders_texture_path, True)\n",
        "print('Recoloring unfinished surface...')\n",
        "image = cv2.imread('/content/unfinished_mark.png')\n",
        "# Convert the image to a NumPy ndarray\n",
        "image_array = np.array(image)\n",
        "rgbImage_int = copyTextureOnto(np.array(image), int_image_rows, int_image_columns, rgbImage_plainTex, double_texScale, 0, 0, 0)\n",
        "int_surfacePixel = rgbImage_int[0]\n",
        "cv2.imwrite('/content/unfinished_texture.png', rgbImage_int[0])\n",
        "\n",
        "print('Recoloring surface...')\n",
        "rgbImage_int_generic = copyTextureOnto(rgbImage_result, int_image_rows, int_image_columns, rgbImage_plainTex, double_texScale, 0, 0, 0)\n",
        "int_surfacePixel = rgbImage_int_generic[1]\n",
        "\n",
        "print('Recoloring feeders...')\n",
        "rgbImage_int_feeders = copyTextureOnto(rgbImage_result, int_image_rows, int_image_columns, rgbImage_feederTex, double_risScale, float('nan'), 0, 0)\n",
        "rgbImage_int_feeders[0] = batchRecolor(rgbImage_int_feeders[0], int_image_rows, int_image_columns, 0, 0, 0, False, 0, 0, float('nan'))\n",
        "int_feedersPixel = rgbImage_int_feeders[1]\n",
        "\n",
        "print('Saving feeders texture...')\n",
        "cv2.imwrite(str_feeders_result_path, rgbImage_int_feeders[0])"
      ],
      "metadata": {
        "id": "5sWlgss_lU5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b4fb234-60bb-4644-dce5-7797f1b10d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OBJ Resolution = 8.331141651479198\n",
            "---->   Generating Texture   <----\n",
            "Recoloring unfinished surface...\n",
            "Scanning row 0/1024\n",
            "Scanning row 100/1024\n",
            "Scanning row 200/1024\n",
            "Scanning row 300/1024\n",
            "Scanning row 400/1024\n",
            "Scanning row 500/1024\n",
            "Scanning row 600/1024\n",
            "Scanning row 700/1024\n",
            "Scanning row 800/1024\n",
            "Scanning row 900/1024\n",
            "Scanning row 1000/1024\n",
            "Recoloring surface...\n",
            "Scanning row 0/1024\n",
            "Scanning row 100/1024\n",
            "Scanning row 200/1024\n",
            "Scanning row 300/1024\n",
            "Scanning row 400/1024\n",
            "Scanning row 500/1024\n",
            "Scanning row 600/1024\n",
            "Scanning row 700/1024\n",
            "Scanning row 800/1024\n",
            "Scanning row 900/1024\n",
            "Scanning row 1000/1024\n",
            "Recoloring feeders...\n",
            "Scanning row 0/1024\n",
            "Scanning row 100/1024\n",
            "Scanning row 200/1024\n",
            "Scanning row 300/1024\n",
            "Scanning row 400/1024\n",
            "Scanning row 500/1024\n",
            "Scanning row 600/1024\n",
            "Scanning row 700/1024\n",
            "Scanning row 800/1024\n",
            "Scanning row 900/1024\n",
            "Scanning row 1000/1024\n",
            "Saving feeders texture...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Calculations\n",
        "Using the number of pixels recolored, and assuming that all faces (and thus pixels) cover a similar area in the texture, one can approximate the area of the actual part that will have to be ground."
      ],
      "metadata": {
        "id": "h9g6kPjDlsyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cost of removing these feeders through cutting them and grinding the area"
      ],
      "metadata": {
        "id": "pZF144BNmE7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('---->   Calculating Cost   <----')\n",
        "\n",
        "# Write Spreadsheet\n",
        "rowNames = ['Surface', 'Cutting Feeders', 'Grinding Feeders']\n",
        "Pixels = [int_surfacePixel, int_feedersPixel, int_feedersPixel]\n",
        "\n",
        "double_surfaceArea = int_surfacePixel / double_mark_resolution\n",
        "double_feedersArea = int_feedersPixel / double_mark_resolution\n",
        "Area_mm2 = [double_surfaceArea, double_feedersArea, double_feedersArea]\n",
        "\n",
        "double_grindingSpeed = 1           # 1 mm per second\n",
        "double_cuttingSpeed = 14 / 60     # 14 mm per minute\n",
        "\n",
        "double_spacing = 1          # #VTK# = vtk_map.spacing.x\n",
        "double_surfaceTime = 0\n",
        "double_feedersTime = (2 * math.sqrt(int_feedersPixel) * double_spacing) / (math.sqrt(math.pi * double_mark_resolution) * double_cuttingSpeed * 3600)\n",
        "double_feedersGrindTime = (2 * math.sqrt(int_feedersPixel) * double_spacing) / (math.sqrt(math.pi * double_mark_resolution) * double_grindingSpeed * 3600)\n",
        "Time_h = [0, double_feedersTime, double_feedersGrindTime]\n",
        "\n",
        "double_surfaceCost = 0\n",
        "double_feederCost = 15          # $15USD per hour\n",
        "Cost = [double_surfaceCost,\n",
        "        double_feederCost * double_feedersTime,\n",
        "        double_feederCost * double_feedersGrindTime]\n",
        "\n",
        "print(f'Operation:   {rowNames}')\n",
        "print(f'Area (px):   {Pixels}')\n",
        "print(f'Area (mm2):  {Area_mm2}')\n",
        "print(f'Time (h):    {Time_h}')\n",
        "print(f'Cost ($USD): {Cost}')"
      ],
      "metadata": {
        "id": "ck6e_nTsl_FK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2eb9ae8-70e5-4dc1-ce9f-d692c24d896c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---->   Calculating Cost   <----\n",
            "Operation:   ['Surface', 'Cutting Feeders', 'Grinding Feeders']\n",
            "Area (px):   [1033917, 14659, 14659]\n",
            "Area (mm2):  [124102.67923081436, 1759.5427629534167, 1759.5427629534167]\n",
            "Time (h):    [0, 0.056347634169331445, 0.013147781306177338]\n",
            "Cost ($USD): [0, 0.8452145125399717, 0.19721671959266007]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vizualization Output\n",
        "\n"
      ],
      "metadata": {
        "id": "ieIl4eBanlTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blender Python code which function included remeshing, UV unwrapping, adding roughness surface"
      ],
      "metadata": {
        "id": "xdzGaOwzEJ45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script = f\"\"\"\n",
        "import bpy\n",
        "\n",
        "# Delete all objects except for the camera and light\n",
        "bpy.ops.object.select_all(action='SELECT')\n",
        "bpy.data.objects['Camera'].select_set(False)\n",
        "bpy.data.objects['Light'].select_set(False)\n",
        "bpy.ops.object.delete()\n",
        "\n",
        "# Import STL mesh and apply remesh modifier\n",
        "bpy.ops.import_mesh.stl(filepath=\"/content/{str_filePath}\",global_scale=0.1)\n",
        "bpy.ops.object.modifier_add(type='REMESH')\n",
        "bpy.context.object.modifiers[\"Remesh\"].mode = 'VOXEL'\n",
        "bpy.context.object.modifiers[\"Remesh\"].voxel_size = {voxel_size}/10\n",
        "bpy.ops.object.modifier_apply(modifier=\"Remesh\")\n",
        "\n",
        "# Unwrap the mesh using Smart UV Project\n",
        "bpy.ops.object.mode_set(mode='EDIT')\n",
        "bpy.ops.mesh.select_all(action='SELECT')\n",
        "bpy.ops.uv.smart_project()\n",
        "bpy.ops.object.mode_set(mode='OBJECT')\n",
        "\n",
        "# Add displacement modifier with surface texture\n",
        "ob = bpy.context.active_object\n",
        "tex = bpy.data.textures.new(name=\"surface texture\", type=\"IMAGE\")\n",
        "img = bpy.data.images.load(filepath=\"/content/unfinished_texture.png\")\n",
        "tex.image = img\n",
        "tex.extension = 'EXTEND'\n",
        "mod = ob.modifiers.new(\"\", 'DISPLACE')\n",
        "mod.texture_coords =  \"UV\"\n",
        "mod.strength = 1\n",
        "mod.mid_level = 0.5\n",
        "mod.texture = tex\n",
        "mod = ob.modifiers.get(\"Displace\")\n",
        "if mod is not None:\n",
        "    bpy.ops.object.modifier_apply(modifier=\"Displace\")\n",
        "\n",
        "# Create new material for the mesh and set surface color and metallic value\n",
        "ob = bpy.context.active_object\n",
        "mat = bpy.data.materials.new(name=\"Material\")\n",
        "mat.use_nodes = True\n",
        "node_tree = mat.node_tree\n",
        "bsdf_node = node_tree.nodes[\"Principled BSDF\"]\n",
        "bsdf_node.inputs[\"Base Color\"].default_value = (0.2, 0.2, 0.2, 1.0)\n",
        "bsdf_node.inputs[\"Metallic\"].default_value = 1\n",
        "if ob.data.materials:\n",
        "    ob.data.materials[0] = mat\n",
        "else:\n",
        "    ob.data.materials.append(mat)\n",
        "\n",
        "bpy.ops.object.mode_set(mode=\"EDIT\")\n",
        "bpy.ops.mesh.subdivide(number_cuts=4)\n",
        "bpy.ops.object.mode_set(mode=\"OBJECT\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "for i in range(0, num_arrays):\n",
        "    script += f\"\"\"\n",
        "bpy.ops.import_mesh.stl(filepath=\"/content/feeder{i}.stl\",global_scale=0.1)\n",
        "\n",
        "bpy.ops.object.modifier_add(type='REMESH')\n",
        "bpy.context.object.modifiers[\"Remesh\"].mode = 'VOXEL'\n",
        "bpy.context.object.modifiers[\"Remesh\"].voxel_size = {voxel_size}/10\n",
        "bpy.ops.object.modifier_apply(modifier=\"Remesh\")\n",
        "\n",
        "# Unwrap the mesh using Smart UV Project\n",
        "bpy.ops.object.mode_set(mode='EDIT')\n",
        "bpy.ops.mesh.select_all(action='SELECT')\n",
        "bpy.ops.uv.smart_project()\n",
        "bpy.ops.object.mode_set(mode='OBJECT')\n",
        "\n",
        "# Add displacement modifier with surface texture\n",
        "ob = bpy.context.active_object\n",
        "tex = bpy.data.textures.new(name=\"surface texture\", type=\"IMAGE\")\n",
        "img = bpy.data.images.load(filepath=\"/content/unfinished_texture.png\")\n",
        "tex.image = img\n",
        "tex.extension = 'EXTEND'\n",
        "mod = ob.modifiers.new(\"\", 'DISPLACE')\n",
        "mod.texture_coords =  \"UV\"\n",
        "mod.strength = 1\n",
        "mod.mid_level = 0.5\n",
        "mod.texture = tex\n",
        "mod = ob.modifiers.get(\"Displace\")\n",
        "if mod is not None:\n",
        "    bpy.ops.object.modifier_apply(modifier=\"Displace\")\n",
        "\n",
        "# Create new material for the mesh and set surface color and metallic value\n",
        "ob = bpy.context.active_object\n",
        "mat = bpy.data.materials.new(name=\"Material{i}\")\n",
        "mat.use_nodes = True\n",
        "node_tree = mat.node_tree\n",
        "bsdf_node = node_tree.nodes[\"Principled BSDF\"]\n",
        "bsdf_node.inputs[\"Base Color\"].default_value = (0.2, 0.2, 0.2, 1.0)\n",
        "bsdf_node.inputs[\"Metallic\"].default_value = 1\n",
        "if ob.data.materials:\n",
        "    ob.data.materials[0] = mat\n",
        "else:\n",
        "    ob.data.materials.append(mat)\n",
        "\n",
        "bpy.ops.object.mode_set(mode=\"EDIT\")\n",
        "bpy.ops.mesh.subdivide(number_cuts=4)\n",
        "bpy.ops.object.mode_set(mode=\"OBJECT\")\n",
        "\"\"\"\n",
        "script +=\"\"\"\n",
        "bpy.ops.export_scene.gltf(filepath=\"/content/unfinished_geometry.glb\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a text file\n",
        "with open('unfinished_geometry.py', 'w') as f:\n",
        "    f.write(script)"
      ],
      "metadata": {
        "id": "2tqa_45vNgNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./$blender_path -b  -noaudio -P \"/content/unfinished_geometry.py\""
      ],
      "metadata": {
        "id": "V4nXVuORNi-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63a693c-6236-403d-987d-0c755bbdf7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blender 3.4.1 (hash 55485cb379f7 built 2022-12-20 00:46:45)\n",
            "Import finished in 0.0044 sec.\n",
            "Import finished in 0.0026 sec.\n",
            "03:42:28 | INFO: Draco mesh compression is available, use library at /content/blender-3.4.1-linux-x64/3.4/python/lib/python3.10/site-packages/libextern_draco.so\n",
            "03:42:28 | INFO: Starting glTF 2.0 export\n",
            "03:42:32 | INFO: Extracting primitive: SA30053 3D MODEL (2)\n",
            "03:43:11 | INFO: Primitives created: 1\n",
            "03:43:13 | INFO: Extracting primitive: feeder0\n",
            "03:43:20 | INFO: Primitives created: 1\n",
            "03:43:26 | INFO: Finished glTF 2.0 export in 57.59981083869934 s\n",
            "\n",
            "\n",
            "Blender quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script = f\"\"\"\n",
        "import bpy\n",
        "# Delete all objects except for the camera and light\n",
        "bpy.ops.object.select_all(action='SELECT')\n",
        "bpy.data.objects['Camera'].select_set(False)\n",
        "bpy.data.objects['Light'].select_set(False)\n",
        "bpy.ops.object.delete()\n",
        "\n",
        "# Import STL mesh and apply remesh modifier\n",
        "bpy.ops.import_mesh.stl(filepath=\"/content/{str_filePath}\",global_scale=0.1)\n",
        "bpy.ops.object.modifier_add(type='REMESH')\n",
        "bpy.context.object.modifiers[\"Remesh\"].mode = 'VOXEL'\n",
        "bpy.context.object.modifiers[\"Remesh\"].voxel_size = {voxel_size}/10\n",
        "bpy.ops.object.modifier_apply(modifier=\"Remesh\")\n",
        "\n",
        "# Unwrap the mesh using Smart UV Project\n",
        "bpy.ops.object.mode_set(mode='EDIT')\n",
        "bpy.ops.mesh.select_all(action='SELECT')\n",
        "bpy.ops.uv.smart_project()\n",
        "bpy.ops.object.mode_set(mode='OBJECT')\n",
        "# Create a new material\n",
        "material = bpy.data.materials.new(name=\"MyMaterial\")\n",
        "\n",
        "# Create a new shader node tree for the material\n",
        "material.use_nodes = True\n",
        "tree = material.node_tree\n",
        "nodes = tree.nodes\n",
        "\n",
        "# Clear existing nodes\n",
        "for node in nodes:\n",
        "    nodes.remove(node)\n",
        "\n",
        "# Create a new Principled BSDF node\n",
        "bsdf_node = nodes.new(type='ShaderNodeBsdfPrincipled')\n",
        "bsdf_node.location = (0, 0)  # Position the node in the node editor\n",
        "\n",
        "# Create a new Image Texture node\n",
        "texture_node = nodes.new(type='ShaderNodeTexImage')\n",
        "texture_node.location = (-200, 0)  # Position the node in the node editor\n",
        "\n",
        "# Set the path to the image texture\n",
        "texture_node.image = bpy.data.images.load(\"/content/result_mark.png\")\n",
        "\n",
        "# Connect the Image Texture node to the Base Color input of the Principled BSDF node\n",
        "base_color_link = tree.links.new(texture_node.outputs['Color'], bsdf_node.inputs['Base Color'])\n",
        "\n",
        "# Create a new Material Output node\n",
        "output_node = nodes.new(type='ShaderNodeOutputMaterial')\n",
        "output_node.location = (200, 0)  # Position the node in the node editor\n",
        "\n",
        "# Connect the Principled BSDF node to the Surface input of the Material Output node\n",
        "surface_link = tree.links.new(bsdf_node.outputs['BSDF'], output_node.inputs['Surface'])\n",
        "\n",
        "# Assign the material to the active object\n",
        "bpy.context.object.data.materials.append(material)\n",
        "\"\"\"\n",
        "script +=\"\"\"\n",
        "bpy.ops.export_scene.gltf(filepath=\"/content/colored_finished_geometry.glb\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a text file\n",
        "with open('colored_finished_geometry.py', 'w') as f:\n",
        "    f.write(script)"
      ],
      "metadata": {
        "id": "Cf_bYTmLeDjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./$blender_path -b  -noaudio -P \"/content/colored_finished_geometry.py\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGkKOZCReh4v",
        "outputId": "209b047d-1d8f-4e06-f5e7-a75300a94d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blender 3.4.1 (hash 55485cb379f7 built 2022-12-20 00:46:45)\n",
            "Import finished in 0.0038 sec.\n",
            "02:57:07 | INFO: Draco mesh compression is available, use library at /content/blender-3.4.1-linux-x64/3.4/python/lib/python3.10/site-packages/libextern_draco.so\n",
            "02:57:07 | INFO: Starting glTF 2.0 export\n",
            "02:57:07 | INFO: Extracting primitive: SA30053 3D MODEL (2)\n",
            "02:57:08 | INFO: Primitives created: 1\n",
            "02:57:08 | INFO: Finished glTF 2.0 export in 1.0693578720092773 s\n",
            "\n",
            "\n",
            "Blender quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "script = f\"\"\"\n",
        "import bpy\n",
        "\n",
        "# Delete all objects except for the camera and light\n",
        "bpy.ops.object.select_all(action='SELECT')\n",
        "bpy.data.objects['Camera'].select_set(False)\n",
        "bpy.data.objects['Light'].select_set(False)\n",
        "bpy.ops.object.delete()\n",
        "\n",
        "# Import STL mesh and apply remesh modifier\n",
        "bpy.ops.import_mesh.stl(filepath=\"/content/{str_filePath}\",global_scale=0.1)\n",
        "bpy.ops.object.modifier_add(type='REMESH')\n",
        "bpy.context.object.modifiers[\"Remesh\"].mode = 'VOXEL'\n",
        "bpy.context.object.modifiers[\"Remesh\"].voxel_size = {voxel_size}/10\n",
        "bpy.ops.object.modifier_apply(modifier=\"Remesh\")\n",
        "\n",
        "# Unwrap the mesh using Smart UV Project\n",
        "bpy.ops.object.mode_set(mode='EDIT')\n",
        "bpy.ops.mesh.select_all(action='SELECT')\n",
        "bpy.ops.uv.smart_project()\n",
        "bpy.ops.object.mode_set(mode='OBJECT')\n",
        "\n",
        "# Add displacement modifier with surface texture\n",
        "ob = bpy.context.active_object\n",
        "tex = bpy.data.textures.new(name=\"surface texture\", type=\"IMAGE\")\n",
        "img = bpy.data.images.load(filepath=\"/content/result_tex.png\")\n",
        "tex.image = img\n",
        "tex.extension = 'EXTEND'\n",
        "mod = ob.modifiers.new(\"\", 'DISPLACE')\n",
        "mod.texture_coords =  \"UV\"\n",
        "mod.strength = 1\n",
        "mod.mid_level = 0.5\n",
        "mod.texture = tex\n",
        "mod = ob.modifiers.get(\"Displace\")\n",
        "if mod is not None:\n",
        "    bpy.ops.object.modifier_apply(modifier=\"Displace\")\n",
        "\n",
        "# Create new material for the mesh and set surface color and metallic value\n",
        "ob = bpy.context.active_object\n",
        "mat = bpy.data.materials.new(name=\"Material\")\n",
        "mat.use_nodes = True\n",
        "node_tree = mat.node_tree\n",
        "bsdf_node = node_tree.nodes[\"Principled BSDF\"]\n",
        "bsdf_node.inputs[\"Base Color\"].default_value = (0.2, 0.2, 0.2, 1.0)\n",
        "bsdf_node.inputs[\"Metallic\"].default_value = 1\n",
        "if ob.data.materials:\n",
        "    ob.data.materials[0] = mat\n",
        "else:\n",
        "    ob.data.materials.append(mat)\n",
        "\n",
        "bpy.ops.object.mode_set(mode=\"EDIT\")\n",
        "bpy.ops.mesh.subdivide(number_cuts=4)\n",
        "bpy.ops.object.mode_set(mode=\"OBJECT\")\n",
        "\n",
        "\"\"\"\n",
        "script +=\"\"\"\n",
        "bpy.ops.export_scene.gltf(filepath=\"/content/textured_finished_geometry.glb\")\n",
        "\"\"\"\n",
        "\n",
        "# Save the script to a text file\n",
        "with open('textured_finished_geometry.py', 'w') as f:\n",
        "    f.write(script)"
      ],
      "metadata": {
        "id": "EIUuUVUAWPQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./$blender_path -b  -noaudio -P \"/content/textured_finished_geometry.py\""
      ],
      "metadata": {
        "id": "qmpTWDqiWgAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eccee3-1155-4261-9341-ad5fe68bc67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blender 3.4.1 (hash 55485cb379f7 built 2022-12-20 00:46:45)\n",
            "Import finished in 0.0040 sec.\n",
            "03:13:49 | INFO: Draco mesh compression is available, use library at /content/blender-3.4.1-linux-x64/3.4/python/lib/python3.10/site-packages/libextern_draco.so\n",
            "03:13:50 | INFO: Starting glTF 2.0 export\n",
            "03:13:55 | INFO: Extracting primitive: SA30053 3D MODEL (2)\n",
            "03:14:33 | INFO: Primitives created: 1\n",
            "03:14:40 | INFO: Finished glTF 2.0 export in 49.95235061645508 s\n",
            "\n",
            "\n",
            "Blender quit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aX9V6_8M5LL4",
        "ZrrWLNVN5pIN",
        "66qilCQiybdm",
        "9GJu8d4HRY4_",
        "sf5VeAJvXyTm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}